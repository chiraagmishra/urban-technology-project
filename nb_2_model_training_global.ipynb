{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "####**GitHub–Colab Integration**\n",
        "This section has a workflow for integrating Google Colab with the project's GitHub repository."
      ],
      "metadata": {
        "id": "NCBgRnZdDi1b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from getpass import getpass"
      ],
      "metadata": {
        "id": "eOlm6WgIRnDQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GitHub config\n",
        "\n",
        "GITHUB_USERNAME = \"chiraagmishra\"\n",
        "REPO_NAME = \"urban-technology-project\"\n",
        "GITHUB_EMAIL = \"chiraag.cm@gmail.com\"\n",
        "GITHUB_NAME = \"Chiraag Mishra\""
      ],
      "metadata": {
        "id": "uYZqO_0t9fwQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "repo_path = f\"/content/{REPO_NAME}\"\n",
        "\n",
        "# Authenticate (token hidden)\n",
        "token = getpass(\"Paste GitHub Personal Access Token: \")\n",
        "\n",
        "# Clone repo with credentials\n",
        "if not os.path.exists(repo_path):\n",
        "    !git clone https://{GITHUB_USERNAME}:{token}@github.com/{GITHUB_USERNAME}/{REPO_NAME}.git\n",
        "else:\n",
        "    print(\"Repository already exists.\")\n",
        "\n",
        "# Navigate and configure\n",
        "%cd {repo_path}\n",
        "\n",
        "!git config --global user.email \"{GITHUB_EMAIL}\"\n",
        "!git config --global user.name \"{GITHUB_NAME}\"\n",
        "!git config --global --add safe.directory {repo_path}\n",
        "\n",
        "print(\"GitHub set-up. Ready for commit & push from Colab.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yxvsmdiGCTKE",
        "outputId": "30d8cb4a-3db0-4381-c7e7-2fc4a06fc531"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Paste GitHub Personal Access Token: ··········\n",
            "Cloning into 'urban-technology-project'...\n",
            "remote: Enumerating objects: 64, done.\u001b[K\n",
            "remote: Counting objects: 100% (64/64), done.\u001b[K\n",
            "remote: Compressing objects: 100% (54/54), done.\u001b[K\n",
            "remote: Total 64 (delta 23), reused 32 (delta 8), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (64/64), 4.73 MiB | 7.08 MiB/s, done.\n",
            "Resolving deltas: 100% (23/23), done.\n",
            "/content/urban-technology-project\n",
            "GitHub set-up. Ready for commit & push from Colab.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Imports and loads**"
      ],
      "metadata": {
        "id": "STqTtvV_l87R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q darts statsforecast"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zBtMDirimDgN",
        "outputId": "6aeb5bc7-f8a3-4cee-9f01-f5efbe2eff8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.3/46.3 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m354.6/354.6 kB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.4/287.4 kB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.7/280.7 kB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.7/204.7 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m825.4/825.4 kB\u001b[0m \u001b[31m64.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.3/37.3 MB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.3/40.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m74.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import os\n",
        "import traceback\n",
        "from datetime import datetime\n",
        "\n",
        "from darts import TimeSeries\n",
        "from darts.models import (\n",
        "    AutoARIMA,\n",
        "    LinearRegressionModel,\n",
        "    RandomForest,\n",
        "    LightGBMModel,\n",
        "    XGBModel\n",
        ")"
      ],
      "metadata": {
        "id": "DHl2_e9wlwVS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1we3V99rkpsV",
        "outputId": "d38e9d8b-1cf5-452c-dd23-cfbd27f560d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Shape: (400, 13)\n",
            "  Period: 2000-2024\n",
            "  States: 16\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv('data/processed/migration_labor_with_features.csv')\n",
        "\n",
        "print(f\"  Shape: {df.shape}\")\n",
        "print(f\"  Period: {df['year'].min()}-{df['year'].max()}\")\n",
        "print(f\"  States: {df['state'].nunique()}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "missing = df.isnull().sum()\n",
        "if missing.sum() > 0:\n",
        "    print(f\"\\nMissing values detected:\")\n",
        "    print(missing[missing > 0])\n",
        "    print(\"\\nDropping rows with missing values...\")\n",
        "    df = df.dropna()\n",
        "    print(f\"New shape: {df.shape}\")\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "1zI3tF-nmSWg",
        "outputId": "64e74372-aadf-4805-eced-a33fb5b2e400"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               state  year  migration_foreign  migration_foreign_male  \\\n",
              "0  Baden-Württemberg  2000               6418                   -1142   \n",
              "1  Baden-Württemberg  2001              24903                   10120   \n",
              "2  Baden-Württemberg  2002              18590                    5913   \n",
              "3  Baden-Württemberg  2003               8036                     -11   \n",
              "4  Baden-Württemberg  2004               3586                   -2034   \n",
              "\n",
              "   migration_foreign_female  migration_german  migration_total  \\\n",
              "0                      7560              4702            11120   \n",
              "1                     14783              -158            24745   \n",
              "2                     12677             -1749            16841   \n",
              "3                      8047             -3749             4287   \n",
              "4                      5620             -5576            -1990   \n",
              "\n",
              "   unemployment_rate  vacancies_total  vacancies_sc  unemployed_count  \\\n",
              "0                5.4            78669         75810            281500   \n",
              "1                4.9            73514         70418            264301   \n",
              "2                5.4            57496         54136            295005   \n",
              "3                6.2            37759         34494            336881   \n",
              "4                6.2            29907         26861            340943   \n",
              "\n",
              "   labor_market_tightness  vacancy_rate  \n",
              "0                0.269306    269.306326  \n",
              "1                0.266430    266.430069  \n",
              "2                0.183508    183.508132  \n",
              "3                0.102392    102.391935  \n",
              "4                0.078784     78.784199  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bc9f0715-5201-4741-a29d-61ce3cb13adf\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>state</th>\n",
              "      <th>year</th>\n",
              "      <th>migration_foreign</th>\n",
              "      <th>migration_foreign_male</th>\n",
              "      <th>migration_foreign_female</th>\n",
              "      <th>migration_german</th>\n",
              "      <th>migration_total</th>\n",
              "      <th>unemployment_rate</th>\n",
              "      <th>vacancies_total</th>\n",
              "      <th>vacancies_sc</th>\n",
              "      <th>unemployed_count</th>\n",
              "      <th>labor_market_tightness</th>\n",
              "      <th>vacancy_rate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Baden-Württemberg</td>\n",
              "      <td>2000</td>\n",
              "      <td>6418</td>\n",
              "      <td>-1142</td>\n",
              "      <td>7560</td>\n",
              "      <td>4702</td>\n",
              "      <td>11120</td>\n",
              "      <td>5.4</td>\n",
              "      <td>78669</td>\n",
              "      <td>75810</td>\n",
              "      <td>281500</td>\n",
              "      <td>0.269306</td>\n",
              "      <td>269.306326</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Baden-Württemberg</td>\n",
              "      <td>2001</td>\n",
              "      <td>24903</td>\n",
              "      <td>10120</td>\n",
              "      <td>14783</td>\n",
              "      <td>-158</td>\n",
              "      <td>24745</td>\n",
              "      <td>4.9</td>\n",
              "      <td>73514</td>\n",
              "      <td>70418</td>\n",
              "      <td>264301</td>\n",
              "      <td>0.266430</td>\n",
              "      <td>266.430069</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Baden-Württemberg</td>\n",
              "      <td>2002</td>\n",
              "      <td>18590</td>\n",
              "      <td>5913</td>\n",
              "      <td>12677</td>\n",
              "      <td>-1749</td>\n",
              "      <td>16841</td>\n",
              "      <td>5.4</td>\n",
              "      <td>57496</td>\n",
              "      <td>54136</td>\n",
              "      <td>295005</td>\n",
              "      <td>0.183508</td>\n",
              "      <td>183.508132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Baden-Württemberg</td>\n",
              "      <td>2003</td>\n",
              "      <td>8036</td>\n",
              "      <td>-11</td>\n",
              "      <td>8047</td>\n",
              "      <td>-3749</td>\n",
              "      <td>4287</td>\n",
              "      <td>6.2</td>\n",
              "      <td>37759</td>\n",
              "      <td>34494</td>\n",
              "      <td>336881</td>\n",
              "      <td>0.102392</td>\n",
              "      <td>102.391935</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Baden-Württemberg</td>\n",
              "      <td>2004</td>\n",
              "      <td>3586</td>\n",
              "      <td>-2034</td>\n",
              "      <td>5620</td>\n",
              "      <td>-5576</td>\n",
              "      <td>-1990</td>\n",
              "      <td>6.2</td>\n",
              "      <td>29907</td>\n",
              "      <td>26861</td>\n",
              "      <td>340943</td>\n",
              "      <td>0.078784</td>\n",
              "      <td>78.784199</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bc9f0715-5201-4741-a29d-61ce3cb13adf')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bc9f0715-5201-4741-a29d-61ce3cb13adf button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bc9f0715-5201-4741-a29d-61ce3cb13adf');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 400,\n  \"fields\": [\n    {\n      \"column\": \"state\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 16,\n        \"samples\": [\n          \"Baden-W\\u00fcrttemberg\",\n          \"Bayern\",\n          \"Hamburg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"year\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7,\n        \"min\": 2000,\n        \"max\": 2024,\n        \"num_unique_values\": 25,\n        \"samples\": [\n          2008,\n          2016,\n          2000\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"migration_foreign\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 37288,\n        \"min\": -7364,\n        \"max\": 309095,\n        \"num_unique_values\": 399,\n        \"samples\": [\n          12295,\n          3603,\n          118\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"migration_foreign_male\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 20256,\n        \"min\": -6474,\n        \"max\": 178910,\n        \"num_unique_values\": 394,\n        \"samples\": [\n          -396,\n          839,\n          -1627\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"migration_foreign_female\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 17688,\n        \"min\": -2560,\n        \"max\": 169527,\n        \"num_unique_values\": 397,\n        \"samples\": [\n          3060,\n          -10,\n          39693\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"migration_german\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9207,\n        \"min\": -37685,\n        \"max\": 82948,\n        \"num_unique_values\": 381,\n        \"samples\": [\n          -3916,\n          -779,\n          -15788\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"migration_total\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 35834,\n        \"min\": -15752,\n        \"max\": 287628,\n        \"num_unique_values\": 397,\n        \"samples\": [\n          6980,\n          1646,\n          69252\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"unemployment_rate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.090866132530583,\n        \"min\": 2.8,\n        \"max\": 20.5,\n        \"num_unique_values\": 136,\n        \"samples\": [\n          12.0,\n          8.1,\n          8.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"vacancies_total\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 33745,\n        \"min\": 2498,\n        \"max\": 169997,\n        \"num_unique_values\": 396,\n        \"samples\": [\n          5840,\n          2755,\n          20160\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"vacancies_sc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 32577,\n        \"min\": 2124,\n        \"max\": 164973,\n        \"num_unique_values\": 400,\n        \"samples\": [\n          25615,\n          2124,\n          51279\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"unemployed_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 179149,\n        \"min\": 32233,\n        \"max\": 1057649,\n        \"num_unique_values\": 399,\n        \"samples\": [\n          63191,\n          114372,\n          276332\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"labor_market_tightness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.11718223605853444,\n        \"min\": 0.0137714205355887,\n        \"max\": 0.6400454522327561,\n        \"num_unique_values\": 400,\n        \"samples\": [\n          0.0833748335920996,\n          0.039675720103112,\n          0.1855695845230211\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"vacancy_rate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 117.18223605853437,\n        \"min\": 13.771420535588726,\n        \"max\": 640.0454522327561,\n        \"num_unique_values\": 400,\n        \"samples\": [\n          83.37483359209966,\n          39.67572010311204,\n          185.56958452302115\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Define covariates & prepare time series**"
      ],
      "metadata": {
        "id": "oHnPt-pMmz7z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TARGET_COL = 'migration_foreign'\n",
        "\n",
        "# Covariates (exogenous variables for hypothesis testing)\n",
        "COVARIATE_COLS = [\n",
        "    'unemployment_rate',        # H1, H2: Core labor market indicator\n",
        "    'vacancies_sc',             # H1: Job demand signal\n",
        "    'labor_market_tightness',   # H2: Key hypothesis variable\n",
        "    'unemployed_count',         # H1, H2: Labor supply\n",
        "    'vacancy_rate'              # Alternative tightness measure\n",
        "]\n",
        "\n",
        "TEST_SIZE = 5"
      ],
      "metadata": {
        "id": "whMd8Lf_nWEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PREPARE TIME SERIES LISTS (One series per state)\n",
        "\n",
        "def prepare_timeseries_lists(df, target_col, covariate_cols):\n",
        "    \"\"\"\n",
        "    Create lists of TimeSeries objects for global model training\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    target_list : list of TimeSeries\n",
        "        One target series per state\n",
        "    covariate_list : list of TimeSeries\n",
        "        One covariate series per state (aligned with targets)\n",
        "    state_names : list of str\n",
        "        State names (for tracking)\n",
        "    \"\"\"\n",
        "    target_list = []\n",
        "    covariate_list = []\n",
        "    state_names = []\n",
        "\n",
        "    states = sorted(df['state'].unique())\n",
        "\n",
        "    for state in states:\n",
        "        state_data = df[df['state'] == state].sort_values('year').copy()\n",
        "\n",
        "        if len(state_data) < 10:\n",
        "            print(f\"Skipping {state}: insufficient data ({len(state_data)} years)\")\n",
        "            continue\n",
        "\n",
        "        state_data['year_dt'] = pd.to_datetime(state_data['year'], format='%Y')\n",
        "\n",
        "        # Target TimeSeries\n",
        "        target_series = TimeSeries.from_dataframe(\n",
        "            state_data,\n",
        "            time_col='year_dt',\n",
        "            value_cols=target_col,\n",
        "            freq='YS'\n",
        "        )\n",
        "\n",
        "        # Covariate TimeSeries\n",
        "        cov_series = TimeSeries.from_dataframe(\n",
        "            state_data,\n",
        "            time_col='year_dt',\n",
        "            value_cols=covariate_cols,\n",
        "            freq='YS'\n",
        "        )\n",
        "\n",
        "        target_list.append(target_series)\n",
        "        covariate_list.append(cov_series)\n",
        "        state_names.append(state)\n",
        "\n",
        "        print(f\"{state:<25} : {len(target_series)} years\")\n",
        "\n",
        "    print(f\"\\nPrepared {len(target_list)} states for training\")\n",
        "    print(f\"  Total data points: {sum(len(ts) for ts in target_list)}\")\n",
        "\n",
        "    return target_list, covariate_list, state_names"
      ],
      "metadata": {
        "id": "SK_JXAjgm0EX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_list, covariate_list, state_names = prepare_timeseries_lists(\n",
        "    df, TARGET_COL, COVARIATE_COLS\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jKgFkI5zn002",
        "outputId": "4f7ffd57-2144-490e-8700-61f353479e46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baden-Württemberg         : 25 years\n",
            "Bayern                    : 25 years\n",
            "Berlin                    : 25 years\n",
            "Brandenburg               : 25 years\n",
            "Bremen                    : 25 years\n",
            "Hamburg                   : 25 years\n",
            "Hessen                    : 25 years\n",
            "Mecklenburg-Vorpommern    : 25 years\n",
            "Niedersachsen             : 25 years\n",
            "Nordrhein-Westfalen       : 25 years\n",
            "Rheinland-Pfalz           : 25 years\n",
            "Saarland                  : 25 years\n",
            "Sachsen                   : 25 years\n",
            "Sachsen-Anhalt            : 25 years\n",
            "Schleswig-Holstein        : 25 years\n",
            "Thüringen                 : 25 years\n",
            "\n",
            "Prepared 16 states for training\n",
            "  Total data points: 400\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Train-test split**"
      ],
      "metadata": {
        "id": "W-wR2CXNoJ6i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_timeseries_lists(target_list, covariate_list, test_size=5):\n",
        "    \"\"\"\n",
        "    Split lists of TimeSeries into train and test sets\n",
        "    We split each state's series at the same point (global model)\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    target_list : list of TimeSeries\n",
        "    covariate_list : list of TimeSeries\n",
        "    test_size : int\n",
        "        Number of years to reserve for testing\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    train_targets : list of TimeSeries\n",
        "    test_targets : list of TimeSeries\n",
        "    train_covariates : list of TimeSeries\n",
        "    test_covariates : list of TimeSeries\n",
        "    \"\"\"\n",
        "    train_targets = []\n",
        "    test_targets = []\n",
        "    train_covariates = []\n",
        "    test_covariates = []\n",
        "\n",
        "    for i, (target, cov) in enumerate(zip(target_list, covariate_list)):\n",
        "        # Split each state's series\n",
        "        train_target = target[:-test_size]\n",
        "        test_target = target[-test_size:]\n",
        "\n",
        "        train_cov = cov[:-test_size]\n",
        "        test_cov = cov[-test_size:]\n",
        "\n",
        "        train_targets.append(train_target)\n",
        "        test_targets.append(test_target)\n",
        "        train_covariates.append(train_cov)\n",
        "        test_covariates.append(test_cov)\n",
        "\n",
        "    # Verify split\n",
        "    print(f\"Split {len(target_list)} states\")\n",
        "    print(f\"\\nPer state:\")\n",
        "    print(f\"  Training years: {len(train_targets[0])}\")\n",
        "    print(f\"  Test years: {len(test_targets[0])}\")\n",
        "\n",
        "    test_years = test_targets[0].time_index.year.tolist()\n",
        "    print(f\"\\nTest period: {test_years}\")\n",
        "\n",
        "    # Total data points\n",
        "    total_train_points = sum(len(ts) for ts in train_targets)\n",
        "    total_test_points = sum(len(ts) for ts in test_targets)\n",
        "\n",
        "    print(f\"\\nTotal data points:\")\n",
        "    print(f\"  Training: {total_train_points} ({len(train_targets)} states × {len(train_targets[0])} years)\")\n",
        "    print(f\"  Test: {total_test_points} ({len(test_targets)} states × {len(test_targets[0])} years)\")\n",
        "\n",
        "    return train_targets, test_targets, train_covariates, test_covariates"
      ],
      "metadata": {
        "id": "WtX4i76CoMT_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_targets, test_targets, train_covariates, test_covariates = split_timeseries_lists(\n",
        "    target_list, covariate_list, test_size=TEST_SIZE\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJLjz3w7oOtc",
        "outputId": "71700248-22b9-4af4-c984-f40cb51925fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Split 16 states\n",
            "\n",
            "Per state:\n",
            "  Training years: 20\n",
            "  Test years: 5\n",
            "\n",
            "Test period: [2020, 2021, 2022, 2023, 2024]\n",
            "\n",
            "Total data points:\n",
            "  Training: 320 (16 states × 20 years)\n",
            "  Test: 80 (16 states × 5 years)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Model Training Setup**"
      ],
      "metadata": {
        "id": "4FkS8fqdqhEl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('models', exist_ok=True)\n",
        "\n",
        "# To store trained models\n",
        "trained_models = {}\n",
        "\n",
        "# To store predictions\n",
        "predictions = {\n",
        "    'train': {},  # In-sample predictions\n",
        "    'test': {}    # Out-of-sample forecasts\n",
        "}\n",
        "\n",
        "# Number of forecast steps\n",
        "n_forecast = len(test_targets[0])"
      ],
      "metadata": {
        "id": "sxhgCoBAqmnC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Baseline Models (No Labor Market Covariates)**\n",
        "\n",
        "Train on concatenated series (average across states). Or, train one AutoARIMA per state and average predictions."
      ],
      "metadata": {
        "id": "6KSdPA2MrCS5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# BASELINE 1: Naive (Persistence Model)\n",
        "# Assumption: y_t+1 = y_t (tomorrow = today)\n",
        "try:\n",
        "    baseline_predictions_test_naive = []\n",
        "\n",
        "    for train_target, test_target in zip(train_targets, test_targets):\n",
        "        # Repeat last training value for all forecast steps\n",
        "        last_value = train_target.last_value()\n",
        "\n",
        "        naive_pred = TimeSeries.from_times_and_values(\n",
        "            times=test_target.time_index,\n",
        "            values=last_value * np.ones(n_forecast)\n",
        "        )\n",
        "        baseline_predictions_test_naive.append(naive_pred)\n",
        "\n",
        "    # Store\n",
        "    trained_models['Naive'] = 'persistence_model'\n",
        "    predictions['test']['Naive'] = baseline_predictions_test_naive\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Naive baseline failed: {e}\")\n",
        "    traceback.print_exc()\n"
      ],
      "metadata": {
        "id": "Ewjs5SdDt3wq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BASELINE 2: AutoARIMA (Univariate Model)\n",
        "try:\n",
        "    baseline_predictions_test_arima = []\n",
        "\n",
        "    for i, (train_target, test_target) in enumerate(zip(train_targets, test_targets)):\n",
        "        # Train AutoARIMA on this state\n",
        "        model_arima = AutoARIMA(\n",
        "            start_p=1,\n",
        "            max_p=3,\n",
        "            start_q=1,\n",
        "            max_q=3,\n",
        "            max_d=2,\n",
        "            seasonal=False,\n",
        "            stepwise=True,\n",
        "            trace=False,\n",
        "            random_state=42\n",
        "        )\n",
        "\n",
        "        model_arima.fit(train_target)\n",
        "\n",
        "        # Predict\n",
        "        pred = model_arima.predict(n=n_forecast)\n",
        "        baseline_predictions_test_arima.append(pred)\n",
        "\n",
        "        if (i + 1) % 5 == 0:\n",
        "            print(f\"  Completed {i + 1}/{len(train_targets)} states\")\n",
        "\n",
        "    # Store\n",
        "    trained_models['AutoARIMA'] = 'per_state_models'\n",
        "    predictions['test']['AutoARIMA'] = baseline_predictions_test_arima\n",
        "\n",
        "    print(f\"AutoARIMA baseline complete\")\n",
        "    print(f\"Trained {len(train_targets)} separate models (one per state)\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"AutoARIMA failed: {e}\")\n",
        "    traceback.print_exc()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qcq7jzOyrN-1",
        "outputId": "78a6602a-7779-4ee1-f5aa-9ed769c48555"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Completed 5/16 states\n",
            "  Completed 10/16 states\n",
            "  Completed 15/16 states\n",
            "AutoARIMA baseline complete\n",
            "Trained 16 separate models (one per state)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Global models with covariates**"
      ],
      "metadata": {
        "id": "1gaG45uTsrV6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training ONE model per algorithm on ALL states simultaneously"
      ],
      "metadata": {
        "id": "U_ZGyAMluoAu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# MODEL 3: Linear Regression (Global)\n",
        "try:\n",
        "    model_lr = LinearRegressionModel(\n",
        "        lags=3,                      # Use 3 past values of target\n",
        "        lags_future_covariates=[0],  # Use current year's labor market data\n",
        "        output_chunk_length=1        # Predict 1 step at a time\n",
        "    )\n",
        "\n",
        "    print(\"Training on all states...\")\n",
        "    model_lr.fit(train_targets, future_covariates=train_covariates)\n",
        "\n",
        "    print(\"Generating predictions...\")\n",
        "    pred_lr = model_lr.predict(\n",
        "        n=n_forecast,\n",
        "        series=train_targets,\n",
        "        future_covariates=test_covariates\n",
        "    )\n",
        "\n",
        "    # Store\n",
        "    trained_models['LinearReg'] = model_lr\n",
        "    predictions['test']['LinearReg'] = pred_lr\n",
        "\n",
        "    print(f\"Linear Regression complete\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Linear Regression failed: {e}\")\n",
        "    traceback.print_exc()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVZgf547ugdQ",
        "outputId": "431a03f7-24d9-4acb-e8b9-f78b0f9cf7dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on all states...\n",
            "Generating predictions...\n",
            "Linear Regression complete\n",
            "Configuration: lags=3, covariates=5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MODEL 4: Random Forest\n",
        "try:\n",
        "    model_rf = RandomForest(\n",
        "        lags=3,\n",
        "        lags_future_covariates=[0],\n",
        "        output_chunk_length=1,\n",
        "        n_estimators=100,\n",
        "        max_depth=5,\n",
        "        min_samples_split=5,\n",
        "        min_samples_leaf=2,\n",
        "        random_state=42,\n",
        "        n_jobs=-1                    # Use all CPU cores\n",
        "    )\n",
        "\n",
        "    print(\"Training on all states...\")\n",
        "    model_rf.fit(train_targets, future_covariates=train_covariates)\n",
        "\n",
        "    print(\"Generating predictions...\")\n",
        "    pred_rf = model_rf.predict(\n",
        "        n=n_forecast,\n",
        "        series=train_targets,\n",
        "        future_covariates=test_covariates\n",
        "    )\n",
        "\n",
        "    # Store\n",
        "    trained_models['RandomForest'] = model_rf\n",
        "    predictions['test']['RandomForest'] = pred_rf\n",
        "\n",
        "    print(f\"Random Forest complete\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Random Forest failed: {e}\")\n",
        "    traceback.print_exc()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DoTHdDIgvrkg",
        "outputId": "a41b25d9-4f88-439b-9c15-ad8d4024bae2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:darts.models.forecasting.random_forest:DeprecationWarning: `RandomForest` is deprecated and will be removed in a future version. Use `RandomForestModel` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on all states...\n",
            "Generating predictions...\n",
            "Random Forest complete\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MODEL 5: XGBoost\n",
        "try:\n",
        "    model_xgb = XGBModel(\n",
        "        lags=3,\n",
        "        lags_future_covariates=[0],\n",
        "        output_chunk_length=1,\n",
        "        n_estimators=100,\n",
        "        max_depth=5,\n",
        "        learning_rate=0.1,\n",
        "        min_child_weight=1,\n",
        "        subsample=0.8,\n",
        "        colsample_bytree=0.8,\n",
        "        random_state=42,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "\n",
        "    print(\"Training on all states...\")\n",
        "    model_xgb.fit(train_targets, future_covariates=train_covariates)\n",
        "\n",
        "    print(\"Generating predictions...\")\n",
        "    pred_xgb = model_xgb.predict(\n",
        "        n=n_forecast,\n",
        "        series=train_targets,\n",
        "        future_covariates=test_covariates\n",
        "    )\n",
        "\n",
        "    # Store\n",
        "    trained_models['XGBoost'] = model_xgb\n",
        "    predictions['test']['XGBoost'] = pred_xgb\n",
        "\n",
        "    print(f\"XGBoost complete\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"XGBoost failed: {e}\")\n",
        "    traceback.print_exc()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vquWdTNgwIaf",
        "outputId": "361dadce-4f52-46a1-807b-abacdee2c7f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on all states...\n",
            "Generating predictions...\n",
            "XGBoost complete\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MODEL 6: LightGBM (Global)\n",
        "try:\n",
        "    model_lgb = LightGBMModel(\n",
        "        lags=3,\n",
        "        lags_future_covariates=[0],\n",
        "        output_chunk_length=1,\n",
        "        n_estimators=100,\n",
        "        max_depth=5,\n",
        "        num_leaves=31,\n",
        "        learning_rate=0.1,\n",
        "        min_child_samples=5,\n",
        "        subsample=0.8,\n",
        "        colsample_bytree=0.8,\n",
        "        random_state=42,\n",
        "        verbose=-1\n",
        "    )\n",
        "\n",
        "    print(\"Training on all states...\")\n",
        "    model_lgb.fit(train_targets, future_covariates=train_covariates)\n",
        "\n",
        "    print(\"Generating predictions...\")\n",
        "    pred_lgb = model_lgb.predict(\n",
        "        n=n_forecast,\n",
        "        series=train_targets,\n",
        "        future_covariates=test_covariates\n",
        "    )\n",
        "\n",
        "    # Store\n",
        "    trained_models['LightGBM'] = model_lgb\n",
        "    predictions['test']['LightGBM'] = pred_lgb\n",
        "\n",
        "    print(f\"LightGBM complete\")\n",
        "    print(f\"Configuration: lags=3, n_estimators=100, max_depth=5\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"LightGBM failed: {e}\")\n",
        "    traceback.print_exc()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K29Fc-MJucIn",
        "outputId": "d3153e8e-1a78-4c64-ffae-df63b0e6eafc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on all states...\n",
            "Generating predictions...\n",
            "LightGBM complete\n",
            "Configuration: lags=3, n_estimators=100, max_depth=5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Save global models**"
      ],
      "metadata": {
        "id": "FwZlgW3jw1dp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('models', exist_ok=True)\n",
        "os.makedirs('results/predictions', exist_ok=True)"
      ],
      "metadata": {
        "id": "GFYLXUWExLdi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save models\n",
        "for model_name, model_obj in trained_models.items():\n",
        "    if isinstance(model_obj, str):\n",
        "        # Skip non-picklable markers (e.g., 'per_state_models', 'persistence_model')\n",
        "        print(f\"{model_name}: {model_obj} (not saved - simple baseline)\")\n",
        "        continue\n",
        "\n",
        "    try:\n",
        "        model_path = f'models/{model_name}_global.pkl'\n",
        "        with open(model_path, 'wb') as f:\n",
        "            pickle.dump(model_obj, f)\n",
        "        print(f\"{model_name}: {model_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"{model_name}: Failed to save - {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4OzyaQOxXBX",
        "outputId": "d1415b69-2f09-4da4-dd2f-eae98db660e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AutoARIMA: per_state_models (not saved - simple baseline)\n",
            "Naive: persistence_model (not saved - simple baseline)\n",
            "LinearReg: models/LinearReg_global.pkl\n",
            "RandomForest: models/RandomForest_global.pkl\n",
            "XGBoost: models/XGBoost_global.pkl\n",
            "LightGBM: models/LightGBM_global.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save Predictions (Test Set)\n",
        "\n",
        "# Saved as pickle (to preserve TimeSeries objects)\n",
        "predictions_path = 'results/predictions/test_predictions.pkl'\n",
        "with open(predictions_path, 'wb') as f:\n",
        "    pickle.dump(predictions['test'], f)\n",
        "print(f\"Test predictions: {predictions_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ReHS0Noxo3m",
        "outputId": "b0073ad4-1d33-4e7c-f7c2-9acb242b35fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test predictions: results/predictions/test_predictions.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save state names for reference\n",
        "state_info = {\n",
        "    'state_names': state_names,\n",
        "    'test_years': test_targets[0].time_index.year.tolist(),\n",
        "    'n_states': len(state_names),\n",
        "    'n_forecast': n_forecast\n",
        "}\n",
        "\n",
        "state_info_path = 'results/predictions/state_info.pkl'\n",
        "with open(state_info_path, 'wb') as f:\n",
        "    pickle.dump(state_info, f)\n",
        "print(f\"State info: {state_info_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vuf2tL_IxtGc",
        "outputId": "7e6daa09-13de-424c-9e76-ef0e9ee48534"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "State info: results/predictions/state_info.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save Predictions as CSV (for easy inspection)\n",
        "prediction_records = []\n",
        "\n",
        "for model_name, pred_list in predictions['test'].items():\n",
        "    for i, (state, pred_series) in enumerate(zip(state_names, pred_list)):\n",
        "        for time_idx, value in zip(pred_series.time_index, pred_series.values()):\n",
        "            prediction_records.append({\n",
        "                'state': state,\n",
        "                'year': time_idx.year,\n",
        "                'model': model_name,\n",
        "                'predicted_migration': value.item()\n",
        "            })\n",
        "\n",
        "df_predictions = pd.DataFrame(prediction_records)\n",
        "\n",
        "# Actual values for comparison\n",
        "actual_records = []\n",
        "for i, (state, test_series) in enumerate(zip(state_names, test_targets)):\n",
        "    for time_idx, value in zip(test_series.time_index, test_series.values()):\n",
        "        actual_records.append({\n",
        "            'state': state,\n",
        "            'year': time_idx.year,\n",
        "            'actual_migration': value.item()\n",
        "        })\n",
        "\n",
        "df_actual = pd.DataFrame(actual_records)\n",
        "\n",
        "# Merge predictions with actuals\n",
        "df_predictions_full = df_predictions.merge(\n",
        "    df_actual,\n",
        "    on=['state', 'year'],\n",
        "    how='left'\n",
        ")\n",
        "\n",
        "csv_path = 'results/predictions/predictions_vs_actual.csv'\n",
        "df_predictions_full.to_csv(csv_path, index=False)\n",
        "print(f\"CSV format: {csv_path}\")\n",
        "\n",
        "print(\"\\nSample predictions (first state, first year):\")\n",
        "sample = df_predictions_full[\n",
        "    (df_predictions_full['state'] == state_names[0]) &\n",
        "    (df_predictions_full['year'] == test_targets[0].time_index.year[0])\n",
        "]\n",
        "print(sample.to_string(index=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2CNLqhKJyBWc",
        "outputId": "bb33d84b-d028-41e6-9025-bb2adbed9088"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV format: results/predictions/predictions_vs_actual.csv\n",
            "\n",
            "Sample predictions (first state, first year):\n",
            "            state  year        model  predicted_migration  actual_migration\n",
            "Baden-Württemberg  2020    AutoARIMA         55147.000000           32258.0\n",
            "Baden-Württemberg  2020        Naive         55147.000000           32258.0\n",
            "Baden-Württemberg  2020    LinearReg         55530.823471           32258.0\n",
            "Baden-Württemberg  2020 RandomForest         82324.599963           32258.0\n",
            "Baden-Württemberg  2020      XGBoost         76441.390625           32258.0\n",
            "Baden-Württemberg  2020     LightGBM        117725.160371           32258.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Summary\n",
        "print(f\"\\nModels Trained:\")\n",
        "for model_name in trained_models.keys():\n",
        "    print(f\"- {model_name}\")\n",
        "\n",
        "print(f\"\\nOutputs Saved:\")\n",
        "print(f\"  • models/*.pkl ({len([m for m in trained_models.values() if not isinstance(m, str)])} files)\")\n",
        "print(f\"  • results/predictions/test_predictions.pkl\")\n",
        "print(f\"  • results/predictions/state_info.pkl\")\n",
        "print(f\"  • results/predictions/predictions_vs_actual.csv\")\n",
        "\n",
        "print(f\"\\nPrediction Details:\")\n",
        "print(f\"  - States: {len(state_names)}\")\n",
        "print(f\"  - Test period: {test_targets[0].time_index.year[0]}-{test_targets[0].time_index.year[-1]}\")\n",
        "print(f\"  - Forecast horizon: {n_forecast} years\")\n",
        "print(f\"  - Total predictions per model: {len(state_names) * n_forecast}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Z6bxvF1xICr",
        "outputId": "794ced9a-d820-4bcf-82e4-7fc8e32b6321"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Models Trained:\n",
            "- AutoARIMA\n",
            "- Naive\n",
            "- LinearReg\n",
            "- RandomForest\n",
            "- XGBoost\n",
            "- LightGBM\n",
            "\n",
            "Outputs Saved:\n",
            "  • models/*.pkl (4 files)\n",
            "  • results/predictions/test_predictions.pkl\n",
            "  • results/predictions/state_info.pkl\n",
            "  • results/predictions/predictions_vs_actual.csv\n",
            "\n",
            "Prediction Details:\n",
            "  - States: 16\n",
            "  - Test period: 2020-2024\n",
            "  - Forecast horizon: 5 years\n",
            "  - Total predictions per model: 80\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8wJ0vnRdmSMF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}