{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "####**GitHub–Colab Integration**\n",
        "This section has a workflow for integrating Google Colab with the project's GitHub repository."
      ],
      "metadata": {
        "id": "NCBgRnZdDi1b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from getpass import getpass"
      ],
      "metadata": {
        "id": "eOlm6WgIRnDQ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GitHub config\n",
        "\n",
        "GITHUB_USERNAME = \"chiraagmishra\"\n",
        "REPO_NAME = \"urban-technology-project\"\n",
        "GITHUB_EMAIL = \"chiraag.cm@gmail.com\"\n",
        "GITHUB_NAME = \"Chiraag Mishra\""
      ],
      "metadata": {
        "id": "uYZqO_0t9fwQ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "repo_path = f\"/content/{REPO_NAME}\"\n",
        "\n",
        "# Authenticate (token hidden)\n",
        "token = getpass(\"Paste GitHub Personal Access Token: \")\n",
        "\n",
        "# Clone repo with credentials\n",
        "if not os.path.exists(repo_path):\n",
        "    !git clone https://{GITHUB_USERNAME}:{token}@github.com/{GITHUB_USERNAME}/{REPO_NAME}.git\n",
        "else:\n",
        "    print(\"Repository already exists.\")\n",
        "\n",
        "# Navigate and configure\n",
        "%cd {repo_path}\n",
        "\n",
        "!git config --global user.email \"{GITHUB_EMAIL}\"\n",
        "!git config --global user.name \"{GITHUB_NAME}\"\n",
        "!git config --global --add safe.directory {repo_path}\n",
        "\n",
        "print(\"GitHub set-up. Ready for commit & push from Colab.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yxvsmdiGCTKE",
        "outputId": "baa0adda-4901-41c7-bcb0-90ee1cf9d255"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Paste GitHub Personal Access Token: ··········\n",
            "Cloning into 'urban-technology-project'...\n",
            "remote: Enumerating objects: 225, done.\u001b[K\n",
            "remote: Counting objects: 100% (225/225), done.\u001b[K\n",
            "remote: Compressing objects: 100% (156/156), done.\u001b[K\n",
            "remote: Total 225 (delta 106), reused 157 (delta 66), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (225/225), 8.22 MiB | 11.70 MiB/s, done.\n",
            "Resolving deltas: 100% (106/106), done.\n",
            "/content/urban-technology-project\n",
            "GitHub set-up. Ready for commit & push from Colab.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### **Imports and loads**"
      ],
      "metadata": {
        "id": "STqTtvV_l87R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q darts statsforecast"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zBtMDirimDgN",
        "outputId": "157f42e5-f3b2-49e3-9089-05973d6d91f9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.3/46.3 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m354.6/354.6 kB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.4/287.4 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.7/280.7 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.7/204.7 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m825.4/825.4 kB\u001b[0m \u001b[31m45.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.3/37.3 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.3/40.3 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m49.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import os\n",
        "import traceback\n",
        "from datetime import datetime\n",
        "\n",
        "from darts import TimeSeries\n",
        "from darts.models import (\n",
        "    AutoARIMA,\n",
        "    LinearRegressionModel,\n",
        "    RandomForest,\n",
        "    LightGBMModel,\n",
        "    XGBModel\n",
        ")"
      ],
      "metadata": {
        "id": "DHl2_e9wlwVS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1we3V99rkpsV",
        "outputId": "0d57168e-0599-4fb6-c1b4-e17382583387"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Shape: (400, 13)\n",
            "  Period: 2000-2024\n",
            "  States: 16\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv('data/processed/migration_labor_with_features.csv')\n",
        "\n",
        "print(f\"  Shape: {df.shape}\")\n",
        "print(f\"  Period: {df['year'].min()}-{df['year'].max()}\")\n",
        "print(f\"  States: {df['state'].nunique()}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "missing = df.isnull().sum()\n",
        "if missing.sum() > 0:\n",
        "    print(f\"\\nMissing values detected:\")\n",
        "    print(missing[missing > 0])\n",
        "    print(\"\\nDropping rows with missing values...\")\n",
        "    df = df.dropna()\n",
        "    print(f\"New shape: {df.shape}\")\n",
        "\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "1zI3tF-nmSWg",
        "outputId": "81c2a684-b14b-40ef-f28e-710fc88e5a5f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 state  year  migration_foreign  migration_foreign_male  \\\n",
              "0    Baden-Württemberg  2000               6418                   -1142   \n",
              "1    Baden-Württemberg  2001              24903                   10120   \n",
              "2    Baden-Württemberg  2002              18590                    5913   \n",
              "3    Baden-Württemberg  2003               8036                     -11   \n",
              "4    Baden-Württemberg  2004               3586                   -2034   \n",
              "..                 ...   ...                ...                     ...   \n",
              "395          Thüringen  2020               5403                    2756   \n",
              "396          Thüringen  2021              11487                    6285   \n",
              "397          Thüringen  2022              40598                   18766   \n",
              "398          Thüringen  2023              18867                   11531   \n",
              "399          Thüringen  2024              11153                    6186   \n",
              "\n",
              "     migration_foreign_female  migration_german  migration_total  \\\n",
              "0                        7560              4702            11120   \n",
              "1                       14783              -158            24745   \n",
              "2                       12677             -1749            16841   \n",
              "3                        8047             -3749             4287   \n",
              "4                        5620             -5576            -1990   \n",
              "..                        ...               ...              ...   \n",
              "395                      2647              -488             4915   \n",
              "396                      5202              -758            10729   \n",
              "397                     21832             -1123            39475   \n",
              "398                      7336              -977            17890   \n",
              "399                      4967             -1067            10086   \n",
              "\n",
              "     unemployment_rate  vacancies_total  vacancies_sc  unemployed_count  \\\n",
              "0                  5.4            78669         75810            281500   \n",
              "1                  4.9            73514         70418            264301   \n",
              "2                  5.4            57496         54136            295005   \n",
              "3                  6.2            37759         34494            336881   \n",
              "4                  6.2            29907         26861            340943   \n",
              "..                 ...              ...           ...               ...   \n",
              "395                6.0            18211         17933             66678   \n",
              "396                5.6            20242         19960             62249   \n",
              "397                5.3            21308         21032             58172   \n",
              "398                5.9            16586         16404             64978   \n",
              "399                6.2            15139         14946             68768   \n",
              "\n",
              "     labor_market_tightness  vacancy_quality_ratio  \n",
              "0                  0.269306               0.963646  \n",
              "1                  0.266430               0.957873  \n",
              "2                  0.183508               0.941545  \n",
              "3                  0.102392               0.913506  \n",
              "4                  0.078784               0.898121  \n",
              "..                      ...                    ...  \n",
              "395                0.268945               0.984680  \n",
              "396                0.320643               0.986020  \n",
              "397                0.361542               0.987001  \n",
              "398                0.252451               0.988967  \n",
              "399                0.217336               0.987186  \n",
              "\n",
              "[400 rows x 13 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4e2d8038-ea39-46db-b450-a6a2071e1230\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>state</th>\n",
              "      <th>year</th>\n",
              "      <th>migration_foreign</th>\n",
              "      <th>migration_foreign_male</th>\n",
              "      <th>migration_foreign_female</th>\n",
              "      <th>migration_german</th>\n",
              "      <th>migration_total</th>\n",
              "      <th>unemployment_rate</th>\n",
              "      <th>vacancies_total</th>\n",
              "      <th>vacancies_sc</th>\n",
              "      <th>unemployed_count</th>\n",
              "      <th>labor_market_tightness</th>\n",
              "      <th>vacancy_quality_ratio</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Baden-Württemberg</td>\n",
              "      <td>2000</td>\n",
              "      <td>6418</td>\n",
              "      <td>-1142</td>\n",
              "      <td>7560</td>\n",
              "      <td>4702</td>\n",
              "      <td>11120</td>\n",
              "      <td>5.4</td>\n",
              "      <td>78669</td>\n",
              "      <td>75810</td>\n",
              "      <td>281500</td>\n",
              "      <td>0.269306</td>\n",
              "      <td>0.963646</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Baden-Württemberg</td>\n",
              "      <td>2001</td>\n",
              "      <td>24903</td>\n",
              "      <td>10120</td>\n",
              "      <td>14783</td>\n",
              "      <td>-158</td>\n",
              "      <td>24745</td>\n",
              "      <td>4.9</td>\n",
              "      <td>73514</td>\n",
              "      <td>70418</td>\n",
              "      <td>264301</td>\n",
              "      <td>0.266430</td>\n",
              "      <td>0.957873</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Baden-Württemberg</td>\n",
              "      <td>2002</td>\n",
              "      <td>18590</td>\n",
              "      <td>5913</td>\n",
              "      <td>12677</td>\n",
              "      <td>-1749</td>\n",
              "      <td>16841</td>\n",
              "      <td>5.4</td>\n",
              "      <td>57496</td>\n",
              "      <td>54136</td>\n",
              "      <td>295005</td>\n",
              "      <td>0.183508</td>\n",
              "      <td>0.941545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Baden-Württemberg</td>\n",
              "      <td>2003</td>\n",
              "      <td>8036</td>\n",
              "      <td>-11</td>\n",
              "      <td>8047</td>\n",
              "      <td>-3749</td>\n",
              "      <td>4287</td>\n",
              "      <td>6.2</td>\n",
              "      <td>37759</td>\n",
              "      <td>34494</td>\n",
              "      <td>336881</td>\n",
              "      <td>0.102392</td>\n",
              "      <td>0.913506</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Baden-Württemberg</td>\n",
              "      <td>2004</td>\n",
              "      <td>3586</td>\n",
              "      <td>-2034</td>\n",
              "      <td>5620</td>\n",
              "      <td>-5576</td>\n",
              "      <td>-1990</td>\n",
              "      <td>6.2</td>\n",
              "      <td>29907</td>\n",
              "      <td>26861</td>\n",
              "      <td>340943</td>\n",
              "      <td>0.078784</td>\n",
              "      <td>0.898121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>395</th>\n",
              "      <td>Thüringen</td>\n",
              "      <td>2020</td>\n",
              "      <td>5403</td>\n",
              "      <td>2756</td>\n",
              "      <td>2647</td>\n",
              "      <td>-488</td>\n",
              "      <td>4915</td>\n",
              "      <td>6.0</td>\n",
              "      <td>18211</td>\n",
              "      <td>17933</td>\n",
              "      <td>66678</td>\n",
              "      <td>0.268945</td>\n",
              "      <td>0.984680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>396</th>\n",
              "      <td>Thüringen</td>\n",
              "      <td>2021</td>\n",
              "      <td>11487</td>\n",
              "      <td>6285</td>\n",
              "      <td>5202</td>\n",
              "      <td>-758</td>\n",
              "      <td>10729</td>\n",
              "      <td>5.6</td>\n",
              "      <td>20242</td>\n",
              "      <td>19960</td>\n",
              "      <td>62249</td>\n",
              "      <td>0.320643</td>\n",
              "      <td>0.986020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>397</th>\n",
              "      <td>Thüringen</td>\n",
              "      <td>2022</td>\n",
              "      <td>40598</td>\n",
              "      <td>18766</td>\n",
              "      <td>21832</td>\n",
              "      <td>-1123</td>\n",
              "      <td>39475</td>\n",
              "      <td>5.3</td>\n",
              "      <td>21308</td>\n",
              "      <td>21032</td>\n",
              "      <td>58172</td>\n",
              "      <td>0.361542</td>\n",
              "      <td>0.987001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>398</th>\n",
              "      <td>Thüringen</td>\n",
              "      <td>2023</td>\n",
              "      <td>18867</td>\n",
              "      <td>11531</td>\n",
              "      <td>7336</td>\n",
              "      <td>-977</td>\n",
              "      <td>17890</td>\n",
              "      <td>5.9</td>\n",
              "      <td>16586</td>\n",
              "      <td>16404</td>\n",
              "      <td>64978</td>\n",
              "      <td>0.252451</td>\n",
              "      <td>0.988967</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>399</th>\n",
              "      <td>Thüringen</td>\n",
              "      <td>2024</td>\n",
              "      <td>11153</td>\n",
              "      <td>6186</td>\n",
              "      <td>4967</td>\n",
              "      <td>-1067</td>\n",
              "      <td>10086</td>\n",
              "      <td>6.2</td>\n",
              "      <td>15139</td>\n",
              "      <td>14946</td>\n",
              "      <td>68768</td>\n",
              "      <td>0.217336</td>\n",
              "      <td>0.987186</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>400 rows × 13 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4e2d8038-ea39-46db-b450-a6a2071e1230')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4e2d8038-ea39-46db-b450-a6a2071e1230 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4e2d8038-ea39-46db-b450-a6a2071e1230');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_7b4845d5-594e-469a-8e80-919b94ef1c6c\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_7b4845d5-594e-469a-8e80-919b94ef1c6c button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 400,\n  \"fields\": [\n    {\n      \"column\": \"state\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 16,\n        \"samples\": [\n          \"Baden-W\\u00fcrttemberg\",\n          \"Bayern\",\n          \"Hamburg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"year\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7,\n        \"min\": 2000,\n        \"max\": 2024,\n        \"num_unique_values\": 25,\n        \"samples\": [\n          2008,\n          2016,\n          2000\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"migration_foreign\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 37288,\n        \"min\": -7364,\n        \"max\": 309095,\n        \"num_unique_values\": 399,\n        \"samples\": [\n          12295,\n          3603,\n          118\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"migration_foreign_male\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 20256,\n        \"min\": -6474,\n        \"max\": 178910,\n        \"num_unique_values\": 394,\n        \"samples\": [\n          -396,\n          839,\n          -1627\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"migration_foreign_female\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 17688,\n        \"min\": -2560,\n        \"max\": 169527,\n        \"num_unique_values\": 397,\n        \"samples\": [\n          3060,\n          -10,\n          39693\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"migration_german\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9207,\n        \"min\": -37685,\n        \"max\": 82948,\n        \"num_unique_values\": 381,\n        \"samples\": [\n          -3916,\n          -779,\n          -15788\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"migration_total\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 35834,\n        \"min\": -15752,\n        \"max\": 287628,\n        \"num_unique_values\": 397,\n        \"samples\": [\n          6980,\n          1646,\n          69252\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"unemployment_rate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.090866132530583,\n        \"min\": 2.8,\n        \"max\": 20.5,\n        \"num_unique_values\": 136,\n        \"samples\": [\n          12.0,\n          8.1,\n          8.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"vacancies_total\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 33745,\n        \"min\": 2498,\n        \"max\": 169997,\n        \"num_unique_values\": 396,\n        \"samples\": [\n          5840,\n          2755,\n          20160\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"vacancies_sc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 32577,\n        \"min\": 2124,\n        \"max\": 164973,\n        \"num_unique_values\": 400,\n        \"samples\": [\n          25615,\n          2124,\n          51279\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"unemployed_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 179149,\n        \"min\": 32233,\n        \"max\": 1057649,\n        \"num_unique_values\": 399,\n        \"samples\": [\n          63191,\n          114372,\n          276332\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"labor_market_tightness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.11718223605853444,\n        \"min\": 0.0137714205355887,\n        \"max\": 0.6400454522327561,\n        \"num_unique_values\": 400,\n        \"samples\": [\n          0.0833748335920996,\n          0.039675720103112,\n          0.1855695845230211\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"vacancy_quality_ratio\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.043161247010997,\n        \"min\": 0.7625088090204369,\n        \"max\": 1.0338335220838053,\n        \"num_unique_values\": 400,\n        \"samples\": [\n          0.8875606375606375,\n          0.763205174272368,\n          0.9368251822350512\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Define covariates & prepare time series**"
      ],
      "metadata": {
        "id": "oHnPt-pMmz7z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TARGET_COL = 'migration_foreign'\n",
        "\n",
        "# Covariates (exogenous variables for hypothesis testing)\n",
        "COVARIATE_COLS = [\n",
        "    'unemployment_rate',        # H1, H2: Core labor market indicator\n",
        "    'vacancies_sc',             # H1: Job demand signal\n",
        "    'labor_market_tightness',   # H2: Key hypothesis variable\n",
        "    'unemployed_count',         # H1, H2: Labor supply\n",
        "    'vacancy_quality_ratio'\n",
        "]\n",
        "\n",
        "TEST_SIZE = 5"
      ],
      "metadata": {
        "id": "whMd8Lf_nWEE"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PREPARE TIME SERIES LISTS (One series per state)\n",
        "\n",
        "def prepare_timeseries_lists(df, target_col, covariate_cols):\n",
        "    \"\"\"\n",
        "    Create lists of TimeSeries objects for global model training\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    target_list : list of TimeSeries\n",
        "        One target series per state\n",
        "    covariate_list : list of TimeSeries\n",
        "        One covariate series per state (aligned with targets)\n",
        "    state_names : list of str\n",
        "        State names (for tracking)\n",
        "    \"\"\"\n",
        "    target_list = []\n",
        "    covariate_list = []\n",
        "    state_names = []\n",
        "\n",
        "    states = sorted(df['state'].unique())\n",
        "\n",
        "    for state in states:\n",
        "        state_data = df[df['state'] == state].sort_values('year').copy()\n",
        "\n",
        "        if len(state_data) < 10:\n",
        "            print(f\"Skipping {state}: insufficient data ({len(state_data)} years)\")\n",
        "            continue\n",
        "\n",
        "        state_data['year_dt'] = pd.to_datetime(state_data['year'], format='%Y')\n",
        "\n",
        "        # Target TimeSeries\n",
        "        target_series = TimeSeries.from_dataframe(\n",
        "            state_data,\n",
        "            time_col='year_dt',\n",
        "            value_cols=target_col,\n",
        "            freq='YS'\n",
        "        )\n",
        "\n",
        "        # Covariate TimeSeries\n",
        "        cov_series = TimeSeries.from_dataframe(\n",
        "            state_data,\n",
        "            time_col='year_dt',\n",
        "            value_cols=covariate_cols,\n",
        "            freq='YS'\n",
        "        )\n",
        "\n",
        "        target_list.append(target_series)\n",
        "        covariate_list.append(cov_series)\n",
        "        state_names.append(state)\n",
        "\n",
        "        print(f\"{state:<25} : {len(target_series)} years\")\n",
        "\n",
        "    print(f\"\\nPrepared {len(target_list)} states for training\")\n",
        "    print(f\"  Total data points: {sum(len(ts) for ts in target_list)}\")\n",
        "\n",
        "    return target_list, covariate_list, state_names"
      ],
      "metadata": {
        "id": "SK_JXAjgm0EX"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_list, covariate_list, state_names = prepare_timeseries_lists(\n",
        "    df, TARGET_COL, COVARIATE_COLS\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jKgFkI5zn002",
        "outputId": "f2e418ab-686d-4663-8584-c6fc649d2ed0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baden-Württemberg         : 25 years\n",
            "Bayern                    : 25 years\n",
            "Berlin                    : 25 years\n",
            "Brandenburg               : 25 years\n",
            "Bremen                    : 25 years\n",
            "Hamburg                   : 25 years\n",
            "Hessen                    : 25 years\n",
            "Mecklenburg-Vorpommern    : 25 years\n",
            "Niedersachsen             : 25 years\n",
            "Nordrhein-Westfalen       : 25 years\n",
            "Rheinland-Pfalz           : 25 years\n",
            "Saarland                  : 25 years\n",
            "Sachsen                   : 25 years\n",
            "Sachsen-Anhalt            : 25 years\n",
            "Schleswig-Holstein        : 25 years\n",
            "Thüringen                 : 25 years\n",
            "\n",
            "Prepared 16 states for training\n",
            "  Total data points: 400\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Train-test split**"
      ],
      "metadata": {
        "id": "W-wR2CXNoJ6i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_timeseries_lists(target_list, covariate_list, test_size=5):\n",
        "    \"\"\"\n",
        "    Split lists of TimeSeries into train and test sets\n",
        "    We split each state's series at the same point (global model)\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    target_list : list of TimeSeries\n",
        "    covariate_list : list of TimeSeries\n",
        "    test_size : int\n",
        "        Number of years to reserve for testing\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    train_targets : list of TimeSeries\n",
        "    test_targets : list of TimeSeries\n",
        "    train_covariates : list of TimeSeries\n",
        "    test_covariates : list of TimeSeries\n",
        "    \"\"\"\n",
        "    train_targets = []\n",
        "    test_targets = []\n",
        "    train_covariates = []\n",
        "    test_covariates = []\n",
        "\n",
        "    for i, (target, cov) in enumerate(zip(target_list, covariate_list)):\n",
        "        # Split each state's series\n",
        "        train_target = target[:-test_size]\n",
        "        test_target = target[-test_size:]\n",
        "\n",
        "        train_cov = cov[:-test_size]\n",
        "        test_cov = cov[-test_size:]\n",
        "\n",
        "        train_targets.append(train_target)\n",
        "        test_targets.append(test_target)\n",
        "        train_covariates.append(train_cov)\n",
        "        test_covariates.append(test_cov)\n",
        "\n",
        "    # Verify split\n",
        "    print(f\"Split {len(target_list)} states\")\n",
        "    print(f\"\\nPer state:\")\n",
        "    print(f\"  Training years: {len(train_targets[0])}\")\n",
        "    print(f\"  Test years: {len(test_targets[0])}\")\n",
        "\n",
        "    test_years = test_targets[0].time_index.year.tolist()\n",
        "    print(f\"\\nTest period: {test_years}\")\n",
        "\n",
        "    # Total data points\n",
        "    total_train_points = sum(len(ts) for ts in train_targets)\n",
        "    total_test_points = sum(len(ts) for ts in test_targets)\n",
        "\n",
        "    print(f\"\\nTotal data points:\")\n",
        "    print(f\"  Training: {total_train_points} ({len(train_targets)} states × {len(train_targets[0])} years)\")\n",
        "    print(f\"  Test: {total_test_points} ({len(test_targets)} states × {len(test_targets[0])} years)\")\n",
        "\n",
        "    return train_targets, test_targets, train_covariates, test_covariates"
      ],
      "metadata": {
        "id": "WtX4i76CoMT_"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_targets, test_targets, train_covariates, test_covariates = split_timeseries_lists(\n",
        "    target_list, covariate_list, test_size=TEST_SIZE\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJLjz3w7oOtc",
        "outputId": "0d9b9de8-8255-4478-d7f4-604bf23d7ef4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Split 16 states\n",
            "\n",
            "Per state:\n",
            "  Training years: 20\n",
            "  Test years: 5\n",
            "\n",
            "Test period: [2020, 2021, 2022, 2023, 2024]\n",
            "\n",
            "Total data points:\n",
            "  Training: 320 (16 states × 20 years)\n",
            "  Test: 80 (16 states × 5 years)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Model Training Setup**"
      ],
      "metadata": {
        "id": "4FkS8fqdqhEl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('models', exist_ok=True)\n",
        "\n",
        "# To store trained models\n",
        "trained_models = {}\n",
        "\n",
        "# To store predictions\n",
        "predictions = {\n",
        "    'train': {},  # In-sample predictions\n",
        "    'test': {}    # Out-of-sample forecasts\n",
        "}\n",
        "\n",
        "# Number of forecast steps\n",
        "n_forecast = len(test_targets[0])"
      ],
      "metadata": {
        "id": "sxhgCoBAqmnC"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Baseline Models (No Labor Market Covariates)**\n",
        "\n",
        "Train on concatenated series (average across states). Or, train one AutoARIMA per state and average predictions."
      ],
      "metadata": {
        "id": "6KSdPA2MrCS5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# BASELINE 1: Naive (Persistence Model)\n",
        "# Assumption: y_t+1 = y_t (tomorrow = today)\n",
        "try:\n",
        "    baseline_predictions_test_naive = []\n",
        "\n",
        "    for i, (train_target, test_target) in enumerate(zip(train_targets, test_targets)):\n",
        "        # Extract last value as a scalar\n",
        "        last_value_array = train_target.values()[-1]\n",
        "\n",
        "        # Handle potential array structure\n",
        "        if isinstance(last_value_array, np.ndarray):\n",
        "            if last_value_array.ndim > 1:\n",
        "                last_value_scalar = float(last_value_array.flatten()[0])\n",
        "            else:\n",
        "                last_value_scalar = float(last_value_array[0])\n",
        "        else:\n",
        "            last_value_scalar = float(last_value_array)\n",
        "\n",
        "        # Create prediction\n",
        "        naive_pred = TimeSeries.from_times_and_values(\n",
        "            times=test_target.time_index,\n",
        "            values=np.full(n_forecast, last_value_scalar)\n",
        "        )\n",
        "\n",
        "        baseline_predictions_test_naive.append(naive_pred)\n",
        "\n",
        "        # Debug output\n",
        "        if (i + 1) % 5 == 0:\n",
        "            print(f\"  State {i+1}/{len(train_targets)}: Last value = {last_value_scalar:.0f}\")\n",
        "\n",
        "    # Store\n",
        "    trained_models['Naive'] = 'persistence_model'\n",
        "    predictions['test']['Naive'] = baseline_predictions_test_naive\n",
        "\n",
        "    print(f\"\\nNaive baseline complete\")\n",
        "    print(f\"  Each state forecasts its own last training value\")\n",
        "\n",
        "    # Verify uniqueness\n",
        "    unique_values = set()\n",
        "    for pred in baseline_predictions_test_naive:\n",
        "        unique_values.add(pred.values()[0, 0])\n",
        "    print(f\"  Unique forecast values across states: {len(unique_values)}/{len(train_targets)}\")\n",
        "\n",
        "    if len(unique_values) < len(train_targets):\n",
        "        print(f\"WARNING: Some states have identical forecasts!\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Naive baseline failed: {e}\")\n",
        "    traceback.print_exc()\n"
      ],
      "metadata": {
        "id": "Ewjs5SdDt3wq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4fe5374-b185-4545-931c-299ac682c252"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  State 5/16: Last value = 3051\n",
            "  State 10/16: Last value = 72980\n",
            "  State 15/16: Last value = 12762\n",
            "\n",
            "Naive baseline complete\n",
            "  Each state forecasts its own last training value\n",
            "  Unique forecast values across states: 16/16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BASELINE 2: AutoARIMA (Univariate Model)\n",
        "try:\n",
        "    baseline_predictions_test_arima = []\n",
        "\n",
        "    arima_forecast_samples = []  # For debugging\n",
        "\n",
        "    for i, (train_target, test_target) in enumerate(zip(train_targets, test_targets)):\n",
        "        state_name = state_names[i]\n",
        "\n",
        "        model_arima = AutoARIMA(\n",
        "            start_p=1,\n",
        "            max_p=3,\n",
        "            start_q=1,\n",
        "            max_q=3,\n",
        "            max_d=2,\n",
        "            seasonal=False,\n",
        "            stepwise=True,\n",
        "            trace=False,\n",
        "            random_state=42\n",
        "        )\n",
        "\n",
        "        model_arima.fit(train_target)\n",
        "\n",
        "        pred = model_arima.predict(n=n_forecast)\n",
        "\n",
        "        baseline_predictions_test_arima.append(pred)\n",
        "\n",
        "        # Collect sample for validation\n",
        "        first_forecast = pred.values()[0, 0]\n",
        "        last_train = train_target.values()[-1, 0]\n",
        "        arima_forecast_samples.append({\n",
        "            'state': state_name,\n",
        "            'last_train': last_train,\n",
        "            'first_forecast': first_forecast,\n",
        "            'forecast_range': pred.values().max() - pred.values().min()\n",
        "        })\n",
        "\n",
        "        if (i + 1) % 5 == 0:\n",
        "            print(f\"  Completed {i + 1}/{len(train_targets)} states\")\n",
        "\n",
        "    # Store\n",
        "    trained_models['AutoARIMA'] = 'per_state_models'\n",
        "    predictions['test']['AutoARIMA'] = baseline_predictions_test_arima\n",
        "\n",
        "    print(f\"\\nAutoARIMA baseline complete\")\n",
        "    print(f\"Trained {len(train_targets)} separate models (one per state)\")\n",
        "\n",
        "    # VALIDATION: Check for suspicious patterns\n",
        "    print(\"\\nValidation Check:\")\n",
        "\n",
        "    # Check 1: Are forecasts unique across states?\n",
        "    unique_forecasts = set([s['first_forecast'] for s in arima_forecast_samples])\n",
        "    print(f\"  Unique first forecasts across states: {len(unique_forecasts)}/{len(train_targets)}\")\n",
        "\n",
        "    if len(unique_forecasts) < len(train_targets):\n",
        "        print(f\"  WARNING: {len(train_targets) - len(unique_forecasts)} states have identical forecasts!\")\n",
        "\n",
        "        # Show which states have same forecast\n",
        "        from collections import Counter\n",
        "        forecast_counts = Counter([s['first_forecast'] for s in arima_forecast_samples])\n",
        "        duplicates = {k: v for k, v in forecast_counts.items() if v > 1}\n",
        "        if duplicates:\n",
        "            print(f\"  Duplicate forecast values: {duplicates}\")\n",
        "\n",
        "    # Check 2: Are forecasts just repeating last value? (random walk)\n",
        "    random_walk_count = 0\n",
        "    for sample in arima_forecast_samples:\n",
        "        if abs(sample['first_forecast'] - sample['last_train']) < 1:  # Essentially same\n",
        "            random_walk_count += 1\n",
        "\n",
        "    print(f\"  States with random walk behavior: {random_walk_count}/{len(train_targets)}\")\n",
        "\n",
        "    if random_walk_count > len(train_targets) * 0.8:\n",
        "        print(f\"  WARNING: {random_walk_count} states defaulting to random walk (constant forecast)\")\n",
        "        print(f\"  This suggests AutoARIMA is fitting I(1) models (differencing) on most states\")\n",
        "\n",
        "    # Check 3: Show sample of forecasts\n",
        "    print(f\"\\n  Sample forecasts (first 3 states):\")\n",
        "    for sample in arima_forecast_samples[:3]:\n",
        "        print(f\"    {sample['state']:<20} Last train: {sample['last_train']:>10.0f}, \"\n",
        "              f\"First forecast: {sample['first_forecast']:>10.0f}, \"\n",
        "              f\"Forecast range: {sample['forecast_range']:>10.0f}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"AutoARIMA failed: {e}\")\n",
        "    traceback.print_exc()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qcq7jzOyrN-1",
        "outputId": "c6ab0f2d-ca8a-4fe4-a3a2-d50690a89378"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Completed 5/16 states\n",
            "  Completed 10/16 states\n",
            "  Completed 15/16 states\n",
            "\n",
            "AutoARIMA baseline complete\n",
            "Trained 16 separate models (one per state)\n",
            "\n",
            "Validation Check:\n",
            "  Unique first forecasts across states: 16/16\n",
            "  States with random walk behavior: 14/16\n",
            "  WARNING: 14 states defaulting to random walk (constant forecast)\n",
            "  This suggests AutoARIMA is fitting I(1) models (differencing) on most states\n",
            "\n",
            "  Sample forecasts (first 3 states):\n",
            "    Baden-Württemberg    Last train:      55147, First forecast:      55147, Forecast range:          0\n",
            "    Bayern               Last train:      63933, First forecast:      63933, Forecast range:          0\n",
            "    Berlin               Last train:      33497, First forecast:      33497, Forecast range:          0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Global models with covariates**"
      ],
      "metadata": {
        "id": "1gaG45uTsrV6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training ONE model per algorithm on ALL states simultaneously"
      ],
      "metadata": {
        "id": "U_ZGyAMluoAu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# MODEL 3: Linear Regression (Global)\n",
        "try:\n",
        "    model_lr = LinearRegressionModel(\n",
        "        lags=3,\n",
        "        lags_future_covariates=[-1, 0],\n",
        "        output_chunk_length=1\n",
        "    )\n",
        "\n",
        "    print(\"Training on all states...\")\n",
        "    # We train using the split train_covariates\n",
        "    model_lr.fit(train_targets, future_covariates=train_covariates)\n",
        "\n",
        "    print(\"Generating predictions...\")\n",
        "    pred_lr = model_lr.predict(\n",
        "        n=n_forecast,\n",
        "        series=train_targets,\n",
        "        # Using covariate_list yo give access to the\n",
        "        # lag values for the very first test year\n",
        "        future_covariates=covariate_list\n",
        "    )\n",
        "\n",
        "    # Store\n",
        "    trained_models['LinearReg'] = model_lr\n",
        "    predictions['test']['LinearReg'] = pred_lr\n",
        "\n",
        "    print(f\"Linear Regression complete\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Linear Regression failed: {e}\")\n",
        "    traceback.print_exc()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qr6bPnSUJ5Cg",
        "outputId": "cc756cb3-4813-418e-bdc4-eb0a0729752b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on all states...\n",
            "Generating predictions...\n",
            "Linear Regression complete\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Simplified tree models to check if they are too complex for the data**"
      ],
      "metadata": {
        "id": "UOF3LJrLg0Kj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# MODEL 4: Random Forest\n",
        "try:\n",
        "    model_rf = RandomForest(\n",
        "        lags=3,\n",
        "        lags_future_covariates=[-1, 0],\n",
        "        output_chunk_length=1,\n",
        "        n_estimators=20,\n",
        "        max_depth=3,\n",
        "        min_samples_split=30,\n",
        "        min_samples_leaf=15,\n",
        "        max_features='sqrt',\n",
        "        random_state=42,\n",
        "        n_jobs=-1                    # Use all CPU cores\n",
        "    )\n",
        "\n",
        "    print(\"Training on all states...\")\n",
        "    model_rf.fit(train_targets, future_covariates=train_covariates)\n",
        "\n",
        "    print(\"Generating predictions...\")\n",
        "    pred_rf = model_rf.predict(\n",
        "        n=n_forecast,\n",
        "        series=train_targets,\n",
        "        future_covariates=covariate_list\n",
        "    )\n",
        "\n",
        "    # Store\n",
        "    trained_models['RandomForest'] = model_rf\n",
        "    predictions['test']['RandomForest'] = pred_rf\n",
        "\n",
        "    print(f\"Random Forest complete\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Random Forest failed: {e}\")\n",
        "    traceback.print_exc()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EuL5sqSUgtwj",
        "outputId": "6338474b-8422-4c5f-ed46-1dface082110"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:darts.models.forecasting.random_forest:DeprecationWarning: `RandomForest` is deprecated and will be removed in a future version. Use `RandomForestModel` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on all states...\n",
            "Generating predictions...\n",
            "Random Forest complete\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MODEL 5: XGBoost\n",
        "try:\n",
        "    model_xgb = XGBModel(\n",
        "        lags=3,\n",
        "        lags_future_covariates=[-1, 0],\n",
        "        output_chunk_length=1,\n",
        "        n_estimators=25,\n",
        "        max_depth=3,\n",
        "        learning_rate=0.1,\n",
        "        min_child_weight=10,\n",
        "        subsample=0.6,\n",
        "        colsample_bytree=0.6,\n",
        "        reg_alpha=2.0,\n",
        "        reg_lambda=3.0,\n",
        "        gamma=1.0,\n",
        "        random_state=42,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "\n",
        "    print(\"Training on all states...\")\n",
        "    model_xgb.fit(train_targets, future_covariates=train_covariates)\n",
        "\n",
        "    print(\"Generating predictions...\")\n",
        "    pred_xgb = model_xgb.predict(\n",
        "        n=n_forecast,\n",
        "        series=train_targets,\n",
        "        future_covariates=covariate_list\n",
        "    )\n",
        "\n",
        "    # Store\n",
        "    trained_models['XGBoost'] = model_xgb\n",
        "    predictions['test']['XGBoost'] = pred_xgb\n",
        "\n",
        "    print(f\"XGBoost complete\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"XGBoost failed: {e}\")\n",
        "    traceback.print_exc()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41SfHZPyg7yF",
        "outputId": "e4f950d6-8e66-4421-c6f7-28ba30c992eb"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on all states...\n",
            "Generating predictions...\n",
            "XGBoost complete\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MODEL 6: LightGBM\n",
        "try:\n",
        "    model_lgb = LightGBMModel(\n",
        "        lags=3,\n",
        "        lags_future_covariates=[-1, 0],\n",
        "        output_chunk_length=1,\n",
        "        n_estimators=25,\n",
        "        max_depth=3,\n",
        "        num_leaves=5,\n",
        "        learning_rate=0.1,\n",
        "        min_child_samples=30,\n",
        "        min_data_in_leaf=15,\n",
        "        subsample=0.6,\n",
        "        colsample_bytree=0.6,\n",
        "        reg_alpha=2.0,\n",
        "        reg_lambda=3.0,\n",
        "        min_gain_to_split=0.2,\n",
        "        random_state=42,\n",
        "        verbose=-1\n",
        "    )\n",
        "\n",
        "    print(\"Training on all states...\")\n",
        "    model_lgb.fit(train_targets, future_covariates=train_covariates)\n",
        "\n",
        "    print(\"Generating predictions...\")\n",
        "    pred_lgb = model_lgb.predict(\n",
        "        n=n_forecast,\n",
        "        series=train_targets,\n",
        "        future_covariates=covariate_list\n",
        "    )\n",
        "\n",
        "    # Store\n",
        "    trained_models['LightGBM'] = model_lgb\n",
        "    predictions['test']['LightGBM'] = pred_lgb\n",
        "\n",
        "    print(f\"LightGBM complete\")\n",
        "    print(f\"Configuration: lags=3, n_estimators=100, max_depth=5\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"LightGBM failed: {e}\")\n",
        "    traceback.print_exc()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRANy4Z1g95H",
        "outputId": "7f5b12a1-9f1a-4f5e-8270-0a67b4c4bc42"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on all states...\n",
            "Generating predictions...\n",
            "LightGBM complete\n",
            "Configuration: lags=3, n_estimators=100, max_depth=5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Save global models**"
      ],
      "metadata": {
        "id": "FwZlgW3jw1dp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('models', exist_ok=True)\n",
        "os.makedirs('results/predictions', exist_ok=True)"
      ],
      "metadata": {
        "id": "GFYLXUWExLdi"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save models\n",
        "for model_name, model_obj in trained_models.items():\n",
        "    if isinstance(model_obj, str):\n",
        "        # Skip non-picklable markers (e.g., 'per_state_models', 'persistence_model')\n",
        "        print(f\"{model_name}: {model_obj} (not saved - simple baseline)\")\n",
        "        continue\n",
        "\n",
        "    try:\n",
        "        model_path = f'models/{model_name}_global.pkl'\n",
        "        with open(model_path, 'wb') as f:\n",
        "            pickle.dump(model_obj, f)\n",
        "        print(f\"{model_name}: {model_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"{model_name}: Failed to save - {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4OzyaQOxXBX",
        "outputId": "27630c40-e023-4935-ee5a-7cb1b78cda27"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive: persistence_model (not saved - simple baseline)\n",
            "AutoARIMA: per_state_models (not saved - simple baseline)\n",
            "LinearReg: models/LinearReg_global.pkl\n",
            "RandomForest: models/RandomForest_global.pkl\n",
            "XGBoost: models/XGBoost_global.pkl\n",
            "LightGBM: models/LightGBM_global.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save Predictions (Test Set)\n",
        "\n",
        "# Saved as pickle (to preserve TimeSeries objects)\n",
        "predictions_path = 'results/predictions/test_predictions.pkl'\n",
        "with open(predictions_path, 'wb') as f:\n",
        "    pickle.dump(predictions['test'], f)\n",
        "print(f\"Test predictions: {predictions_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ReHS0Noxo3m",
        "outputId": "042c56ad-f878-45e9-cccf-244dc6265fdf"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test predictions: results/predictions/test_predictions.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save state names for reference\n",
        "state_info = {\n",
        "    'state_names': state_names,\n",
        "    'test_years': test_targets[0].time_index.year.tolist(),\n",
        "    'n_states': len(state_names),\n",
        "    'n_forecast': n_forecast\n",
        "}\n",
        "\n",
        "state_info_path = 'results/predictions/state_info.pkl'\n",
        "with open(state_info_path, 'wb') as f:\n",
        "    pickle.dump(state_info, f)\n",
        "print(f\"State info: {state_info_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vuf2tL_IxtGc",
        "outputId": "45b0e657-6b9f-4f96-d952-7c11a6165405"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "State info: results/predictions/state_info.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save Predictions as CSV (for easy inspection)\n",
        "prediction_records = []\n",
        "\n",
        "for model_name, pred_list in predictions['test'].items():\n",
        "    for i, (state, pred_series) in enumerate(zip(state_names, pred_list)):\n",
        "        for time_idx, value in zip(pred_series.time_index, pred_series.values()):\n",
        "            prediction_records.append({\n",
        "                'state': state,\n",
        "                'year': time_idx.year,\n",
        "                'model': model_name,\n",
        "                'predicted_migration': value.item()\n",
        "            })\n",
        "\n",
        "df_predictions = pd.DataFrame(prediction_records)\n",
        "\n",
        "# Actual values for comparison\n",
        "actual_records = []\n",
        "for i, (state, test_series) in enumerate(zip(state_names, test_targets)):\n",
        "    for time_idx, value in zip(test_series.time_index, test_series.values()):\n",
        "        actual_records.append({\n",
        "            'state': state,\n",
        "            'year': time_idx.year,\n",
        "            'actual_migration': value.item()\n",
        "        })\n",
        "\n",
        "df_actual = pd.DataFrame(actual_records)\n",
        "\n",
        "# Merge predictions with actuals\n",
        "df_predictions_full = df_predictions.merge(\n",
        "    df_actual,\n",
        "    on=['state', 'year'],\n",
        "    how='left'\n",
        ")\n",
        "\n",
        "csv_path = 'results/predictions/predictions_vs_actual.csv'\n",
        "df_predictions_full.to_csv(csv_path, index=False)\n",
        "print(f\"CSV format: {csv_path}\")\n",
        "\n",
        "print(\"\\nSample predictions (first state, first year):\")\n",
        "sample = df_predictions_full[\n",
        "    (df_predictions_full['state'] == state_names[0]) &\n",
        "    (df_predictions_full['year'] == test_targets[0].time_index.year[0])\n",
        "]\n",
        "print(sample.to_string(index=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2CNLqhKJyBWc",
        "outputId": "03dc054a-1be7-48b8-bb57-9413518540a3"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV format: results/predictions/predictions_vs_actual.csv\n",
            "\n",
            "Sample predictions (first state, first year):\n",
            "            state  year        model  predicted_migration  actual_migration\n",
            "Baden-Württemberg  2020        Naive         55147.000000           32258.0\n",
            "Baden-Württemberg  2020    AutoARIMA         55147.000000           32258.0\n",
            "Baden-Württemberg  2020    LinearReg         35964.244314           32258.0\n",
            "Baden-Württemberg  2020 RandomForest         76251.654133           32258.0\n",
            "Baden-Württemberg  2020      XGBoost         61222.039062           32258.0\n",
            "Baden-Württemberg  2020     LightGBM         72390.718607           32258.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Summary\n",
        "print(f\"\\nModels Trained:\")\n",
        "for model_name in trained_models.keys():\n",
        "    print(f\"- {model_name}\")\n",
        "\n",
        "print(f\"\\nOutputs Saved:\")\n",
        "print(f\"  • models/*.pkl ({len([m for m in trained_models.values() if not isinstance(m, str)])} files)\")\n",
        "print(f\"  • results/predictions/test_predictions.pkl\")\n",
        "print(f\"  • results/predictions/state_info.pkl\")\n",
        "print(f\"  • results/predictions/predictions_vs_actual.csv\")\n",
        "\n",
        "print(f\"\\nPrediction Details:\")\n",
        "print(f\"  - States: {len(state_names)}\")\n",
        "print(f\"  - Test period: {test_targets[0].time_index.year[0]}-{test_targets[0].time_index.year[-1]}\")\n",
        "print(f\"  - Forecast horizon: {n_forecast} years\")\n",
        "print(f\"  - Total predictions per model: {len(state_names) * n_forecast}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Z6bxvF1xICr",
        "outputId": "e6abcd96-5689-40a6-8911-035f10143277"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Models Trained:\n",
            "- Naive\n",
            "- AutoARIMA\n",
            "- LinearReg\n",
            "- RandomForest\n",
            "- XGBoost\n",
            "- LightGBM\n",
            "\n",
            "Outputs Saved:\n",
            "  • models/*.pkl (4 files)\n",
            "  • results/predictions/test_predictions.pkl\n",
            "  • results/predictions/state_info.pkl\n",
            "  • results/predictions/predictions_vs_actual.csv\n",
            "\n",
            "Prediction Details:\n",
            "  - States: 16\n",
            "  - Test period: 2020-2024\n",
            "  - Forecast horizon: 5 years\n",
            "  - Total predictions per model: 80\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "It7RXErEuD6z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}