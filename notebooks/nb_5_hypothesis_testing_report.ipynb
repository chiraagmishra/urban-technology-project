{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "####**GitHub–Colab Integration**\n",
        "This section has a workflow for integrating Google Colab with the project's GitHub repository."
      ],
      "metadata": {
        "id": "NCBgRnZdDi1b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from getpass import getpass"
      ],
      "metadata": {
        "id": "eOlm6WgIRnDQ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GitHub config\n",
        "\n",
        "GITHUB_USERNAME = \"chiraagmishra\"\n",
        "REPO_NAME = \"urban-technology-project\"\n",
        "GITHUB_EMAIL = \"chiraag.cm@gmail.com\"\n",
        "GITHUB_NAME = \"Chiraag Mishra\""
      ],
      "metadata": {
        "id": "uYZqO_0t9fwQ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "repo_path = f\"/content/{REPO_NAME}\"\n",
        "\n",
        "# Authenticate (token hidden)\n",
        "token = getpass(\"Paste GitHub Personal Access Token: \")\n",
        "\n",
        "# Clone repo with credentials\n",
        "if not os.path.exists(repo_path):\n",
        "    !git clone https://{GITHUB_USERNAME}:{token}@github.com/{GITHUB_USERNAME}/{REPO_NAME}.git\n",
        "else:\n",
        "    print(\"Repository already exists.\")\n",
        "\n",
        "# Navigate and configure\n",
        "%cd {repo_path}\n",
        "\n",
        "!git config --global user.email \"{GITHUB_EMAIL}\"\n",
        "!git config --global user.name \"{GITHUB_NAME}\"\n",
        "!git config --global --add safe.directory {repo_path}\n",
        "\n",
        "print(\"GitHub set-up. Ready for commit & push from Colab.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yxvsmdiGCTKE",
        "outputId": "0b359ab1-5b51-452b-971a-be7362cfbbfc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Paste GitHub Personal Access Token: ··········\n",
            "Cloning into 'urban-technology-project'...\n",
            "remote: Enumerating objects: 87, done.\u001b[K\n",
            "remote: Counting objects: 100% (87/87), done.\u001b[K\n",
            "remote: Compressing objects: 100% (75/75), done.\u001b[K\n",
            "remote: Total 87 (delta 26), reused 53 (delta 9), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (87/87), 4.92 MiB | 9.09 MiB/s, done.\n",
            "Resolving deltas: 100% (26/26), done.\n",
            "/content/urban-technology-project\n",
            "GitHub set-up. Ready for commit & push from Colab.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Setup and load results**"
      ],
      "metadata": {
        "id": "xorbqRp11-r_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pickle\n",
        "import os\n",
        "from scipy import stats\n",
        "from datetime import datetime"
      ],
      "metadata": {
        "id": "snbNKVbm2f40"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load processed data with features\n",
        "df_features = pd.read_csv('data/processed/migration_labor_with_features.csv')\n",
        "print(f\"Features data: {df_features.shape}\")\n",
        "\n",
        "# Load model performance metrics\n",
        "df_metrics = pd.read_csv('results/metrics/model_performance_by_state.csv')\n",
        "print(f\"Model metrics: {df_metrics.shape}\")\n",
        "\n",
        "# Load feature importance\n",
        "feature_importance_files = [f for f in os.listdir('results/explainability')\n",
        "                            if f.endswith('_feature_importance.csv')]\n",
        "\n",
        "feature_importance_dict = {}\n",
        "for file in feature_importance_files:\n",
        "    model_name = file.replace('_feature_importance.csv', '')\n",
        "    df_importance = pd.read_csv(f'results/explainability/{file}')\n",
        "    feature_importance_dict[model_name] = df_importance\n",
        "    print(f\"Feature importance: {model_name}\")\n",
        "\n",
        "# Load state info\n",
        "with open('results/predictions/state_info.pkl', 'rb') as f:\n",
        "    state_info = pickle.load(f)\n",
        "\n",
        "state_names = state_info['state_names']\n",
        "test_years = state_info['test_years']\n",
        "\n",
        "print(f\"\\nAll results loaded successfully\")\n",
        "print(f\"  States: {len(state_names)}\")\n",
        "print(f\"  Test period: {test_years[0]}-{test_years[-1]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iiGvi6c62FDe",
        "outputId": "4f362fcc-e202-4aa3-89c5-908e14cf411a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features data: (400, 13)\n",
            "Model metrics: (96, 12)\n",
            "Feature importance: LinearReg\n",
            "\n",
            "All results loaded successfully\n",
            "  States: 16\n",
            "  Test period: 2020-2024\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **H1: Job Vacancies Predict Migration**\n",
        "States with higher job vacancies attract more foreign migrants (Positive correlation bw vacancies_sc and migration_foreign)"
      ],
      "metadata": {
        "id": "RTdFGKxb2IY5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation for each state\n",
        "h1_correlations = []\n",
        "\n",
        "for state in df_features['state'].unique():\n",
        "    state_data = df_features[df_features['state'] == state].copy()\n",
        "\n",
        "    if len(state_data) >= 5:\n",
        "        # Pearson correlation\n",
        "        corr, p_value = stats.pearsonr(\n",
        "            state_data['vacancies_sc'],\n",
        "            state_data['migration_foreign']\n",
        "        )\n",
        "\n",
        "        h1_correlations.append({\n",
        "            'state': state,\n",
        "            'correlation': corr,\n",
        "            'p_value': p_value,\n",
        "            'significant': p_value < 0.05\n",
        "        })\n",
        "\n",
        "df_h1 = pd.DataFrame(h1_correlations)"
      ],
      "metadata": {
        "id": "I0EyJVCb2OuR"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nCorrelation Analysis (vacancies_sc vs migration_foreign):\")\n",
        "print(f\"   Mean correlation:   {df_h1['correlation'].mean():.3f}\")\n",
        "print(f\"   Median correlation: {df_h1['correlation'].median():.3f}\")\n",
        "print(f\"   Std deviation:      {df_h1['correlation'].std():.3f}\")\n",
        "print(f\"   Min correlation:    {df_h1['correlation'].min():.3f}\")\n",
        "print(f\"   Max correlation:    {df_h1['correlation'].max():.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AtfkNkpn3edf",
        "outputId": "e1af221a-ea52-4285-d4e4-6a2229829725"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Correlation Analysis (vacancies_sc vs migration_foreign):\n",
            "   Mean correlation:   0.640\n",
            "   Median correlation: 0.681\n",
            "   Std deviation:      0.139\n",
            "   Min correlation:    0.150\n",
            "   Max correlation:    0.755\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "positive_count = (df_h1['correlation'] > 0).sum()\n",
        "significant_positive = ((df_h1['correlation'] > 0) & (df_h1['significant'])).sum()\n",
        "\n",
        "print(f\"\\nDirectional Analysis:\")\n",
        "print(f\"   Positive correlations: {positive_count}/{len(df_h1)} states ({positive_count/len(df_h1)*100:.1f}%)\")\n",
        "print(f\"   Significant positive:  {significant_positive}/{len(df_h1)} states ({significant_positive/len(df_h1)*100:.1f}%)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZJphmlV3ngk",
        "outputId": "6037d1f9-79a2-437a-b995-9b56e1598ef3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Directional Analysis:\n",
            "   Positive correlations: 16/16 states (100.0%)\n",
            "   Significant positive:  15/16 states (93.8%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# One-sample t-test: Is mean correlation significantly different from 0?\n",
        "t_stat_h1, p_value_h1 = stats.ttest_1samp(df_h1['correlation'], 0)\n",
        "\n",
        "print(f\"\\nStatistical Test (One-sample t-test):\")\n",
        "print(f\"   H0: Mean correlation = 0 (no relationship)\")\n",
        "print(f\"   Ha: Mean correlation ≠ 0 (relationship exists)\")\n",
        "print(f\"   t-statistic: {t_stat_h1:.3f}\")\n",
        "print(f\"   p-value:     {p_value_h1:}\")\n",
        "\n",
        "if p_value_h1 < 0.001:\n",
        "    print(f\"   Result: STRONGLY SIGNIFICANT (p < 0.001)\")\n",
        "elif p_value_h1 < 0.01:\n",
        "    print(f\"   Result: VERY SIGNIFICANT (p < 0.01)\")\n",
        "elif p_value_h1 < 0.05:\n",
        "    print(f\"   Result: SIGNIFICANT (p < 0.05)\")\n",
        "else:\n",
        "    print(f\"   Result: NOT SIGNIFICANT (p >= 0.05)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8IKUH9y3bYq",
        "outputId": "11307680-90dc-4f97-ef51-29ff8801cd6f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Statistical Test (One-sample t-test):\n",
            "   H0: Mean correlation = 0 (no relationship)\n",
            "   Ha: Mean correlation ≠ 0 (relationship exists)\n",
            "   t-statistic: 18.422\n",
            "   p-value:     1.0344758080389701e-11\n",
            "   Result: STRONGLY SIGNIFICANT (p < 0.001)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Effect size (Cohen's d)\n",
        "cohen_d_h1 = df_h1['correlation'].mean() / df_h1['correlation'].std()\n",
        "print(f\"\\nEffect Size (Cohen's d): {cohen_d_h1:.3f}\")\n",
        "if abs(cohen_d_h1) >= 0.8:\n",
        "    print(f\"   Interpretation: LARGE effect\")\n",
        "elif abs(cohen_d_h1) >= 0.5:\n",
        "    print(f\"   Interpretation: MEDIUM effect\")\n",
        "else:\n",
        "    print(f\"   Interpretation: SMALL effect\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9lT5Oze32zZ",
        "outputId": "5ba79a6d-7361-48a3-9ba8-6295a8a6663c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Effect Size (Cohen's d): 4.605\n",
            "   Interpretation: LARGE effect\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if p_value_h1 < 0.05 and df_h1['correlation'].mean() > 0:\n",
        "    print(\"HYPOTHESIS 1 SUPPORTED\")\n",
        "    print(\"   Job vacancies positively correlate with foreign migration\")\n",
        "    print(\"   across all German states with statistical significance.\")\n",
        "else:\n",
        "    print(\"HYPOTHESIS 1 NOT SUPPORTED\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8KT26vz3-ed",
        "outputId": "459a1ebc-2893-46ba-bec3-adfd1275be34"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HYPOTHESIS 1 SUPPORTED\n",
            "   Job vacancies positively correlate with foreign migration\n",
            "   across all German states with statistical significance.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.mkdir('results/hypothesis_testing')\n",
        "df_h1.to_csv('results/hypothesis_testing/h1_correlations.csv', index=False)\n",
        "print(f\"\\nSaved: results/hypothesis_testing/h1_correlations.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCpKFA3_4Fhw",
        "outputId": "1a04dbc4-5d11-4f86-9eb7-63067c65f00b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Saved: results/hypothesis_testing/h1_correlations.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **H2: Labor Market Tightness**\n",
        "States with tighter labor markets attract more foreign migrants (positive correlation between labor_market_tighness and migration_foreign)"
      ],
      "metadata": {
        "id": "zeSKJBbh2P6b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "h2_correlations = []\n",
        "\n",
        "for state in df_features['state'].unique():\n",
        "    state_data = df_features[df_features['state'] == state].copy()\n",
        "\n",
        "    if len(state_data) >= 5:\n",
        "        # Pearson correlation\n",
        "        corr, p_value = stats.pearsonr(\n",
        "            state_data['labor_market_tightness'],\n",
        "            state_data['migration_foreign']\n",
        "        )\n",
        "\n",
        "        h2_correlations.append({\n",
        "            'state': state,\n",
        "            'correlation': corr,\n",
        "            'p_value': p_value,\n",
        "            'significant': p_value < 0.05\n",
        "        })\n",
        "\n",
        "df_h2 = pd.DataFrame(h2_correlations)"
      ],
      "metadata": {
        "id": "WA986Syy4ieN"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nCorrelation Analysis (labor_market_tightness vs migration_foreign):\")\n",
        "print(f\"   Mean correlation:   {df_h2['correlation'].mean():.3f}\")\n",
        "print(f\"   Median correlation: {df_h2['correlation'].median():.3f}\")\n",
        "print(f\"   Std deviation:      {df_h2['correlation'].std():.3f}\")\n",
        "print(f\"   Min correlation:    {df_h2['correlation'].min():.3f}\")\n",
        "print(f\"   Max correlation:    {df_h2['correlation'].max():.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aazb6E5N4mxX",
        "outputId": "96f1fa72-e216-48c1-ae0e-39320c48fe6d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Correlation Analysis (labor_market_tightness vs migration_foreign):\n",
            "   Mean correlation:   0.639\n",
            "   Median correlation: 0.675\n",
            "   Std deviation:      0.132\n",
            "   Min correlation:    0.176\n",
            "   Max correlation:    0.745\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Count positive correlations\n",
        "positive_count = (df_h2['correlation'] > 0).sum()\n",
        "significant_positive = ((df_h2['correlation'] > 0) & (df_h2['significant'])).sum()\n",
        "\n",
        "print(f\"\\nDirectional Analysis:\")\n",
        "print(f\"   Positive correlations: {positive_count}/{len(df_h2)} states ({positive_count/len(df_h2)*100:.1f}%)\")\n",
        "print(f\"   Significant positive:  {significant_positive}/{len(df_h2)} states ({significant_positive/len(df_h2)*100:.1f}%)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdpUbrIG4vUM",
        "outputId": "cbc15152-ddb9-4b72-8f20-f9efabddf470"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Directional Analysis:\n",
            "   Positive correlations: 16/16 states (100.0%)\n",
            "   Significant positive:  15/16 states (93.8%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# One-sample t-test\n",
        "t_stat_h2, p_value_h2 = stats.ttest_1samp(df_h2['correlation'], 0)\n",
        "\n",
        "print(f\"\\nStatistical Test (One-sample t-test):\")\n",
        "print(f\"   H0: Mean correlation = 0 (no relationship)\")\n",
        "print(f\"   Ha: Mean correlation ≠ 0 (relationship exists)\")\n",
        "print(f\"   t-statistic: {t_stat_h2:.3f}\")\n",
        "print(f\"   p-value:     {p_value_h2:}\")\n",
        "\n",
        "if p_value_h2 < 0.001:\n",
        "    print(f\"   Result: STRONGLY SIGNIFICANT (p < 0.001)\")\n",
        "elif p_value_h2 < 0.01:\n",
        "    print(f\"   Result: VERY SIGNIFICANT (p < 0.01)\")\n",
        "elif p_value_h2 < 0.05:\n",
        "    print(f\"   Result: SIGNIFICANT (p < 0.05)\")\n",
        "else:\n",
        "    print(f\"   Result: NOT SIGNIFICANT (p >= 0.05)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_fo-YKm47Fq",
        "outputId": "0edac9e8-7893-4b53-df69-c3cb7ead45e1"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Statistical Test (One-sample t-test):\n",
            "   H0: Mean correlation = 0 (no relationship)\n",
            "   Ha: Mean correlation ≠ 0 (relationship exists)\n",
            "   t-statistic: 19.384\n",
            "   p-value:     4.96364592987353e-12\n",
            "   Result: STRONGLY SIGNIFICANT (p < 0.001)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Effect size\n",
        "cohen_d_h2 = df_h2['correlation'].mean() / df_h2['correlation'].std()\n",
        "print(f\"\\nEffect Size (Cohen's d): {cohen_d_h2:.3f}\")\n",
        "if abs(cohen_d_h2) >= 0.8:\n",
        "    print(f\"   Interpretation: LARGE effect\")\n",
        "elif abs(cohen_d_h2) >= 0.5:\n",
        "    print(f\"   Interpretation: MEDIUM effect\")\n",
        "else:\n",
        "    print(f\"   Interpretation: SMALL effect\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2BDBHgV4_e0",
        "outputId": "14ad633c-9794-4e96-c640-2cbce6f8f888"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Effect Size (Cohen's d): 4.846\n",
            "   Interpretation: LARGE effect\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if p_value_h2 < 0.05 and df_h2['correlation'].mean() > 0:\n",
        "    print(\"HYPOTHESIS 2 SUPPORTED\")\n",
        "    print(\"   Labor market tightness positively correlates with foreign migration\")\n",
        "    print(\"   across all German states with statistical significance.\")\n",
        "else:\n",
        "    print(\"HYPOTHESIS 2 NOT SUPPORTED\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YfpJwfR2T_s",
        "outputId": "591134c9-c7d2-43f7-df54-3483dbc7b3a0"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HYPOTHESIS 2 SUPPORTED\n",
            "   Labor market tightness positively correlates with foreign migration\n",
            "   across all German states with statistical significance.\n",
            "\n",
            " Saved: results/hypothesis_testing/h2_correlations.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_h2.to_csv('results/hypothesis_testing/h2_correlations.csv', index=False)\n",
        "print(f\"\\n Saved: results/hypothesis_testing/h2_correlations.csv\")"
      ],
      "metadata": {
        "id": "v1zvxUKn5Gb2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Model Comparison**\n",
        "H3: Test to see if adding labor market variables improved forecasting accuracy"
      ],
      "metadata": {
        "id": "MeR8k5Hj5Hye"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Baseline models (no labor market covariates)\n",
        "baseline_models = ['Naive', 'AutoARIMA']\n",
        "\n",
        "# Global models (with labor market covariates)\n",
        "global_models = ['LinearReg', 'RandomForest', 'XGBoost', 'LightGBM']\n",
        "\n",
        "state_comparison = []\n",
        "\n",
        "for state in state_names:\n",
        "    state_metrics = df_metrics[df_metrics['state'] == state]\n",
        "\n",
        "    # Best baseline\n",
        "    baseline_data = state_metrics[state_metrics['model'].isin(baseline_models)]\n",
        "    if len(baseline_data) > 0:\n",
        "        best_baseline_rmse = baseline_data['RMSE'].min()\n",
        "        best_baseline_model = baseline_data.loc[baseline_data['RMSE'].idxmin(), 'model']\n",
        "    else:\n",
        "        continue\n",
        "\n",
        "    # Best global model\n",
        "    global_data = state_metrics[state_metrics['model'].isin(global_models)]\n",
        "    if len(global_data) > 0:\n",
        "        best_global_rmse = global_data['RMSE'].min()\n",
        "        best_global_model = global_data.loc[global_data['RMSE'].idxmin(), 'model']\n",
        "    else:\n",
        "        continue\n",
        "\n",
        "    # Calculate improvement\n",
        "    improvement_pct = ((best_baseline_rmse - best_global_rmse) / best_baseline_rmse) * 100\n",
        "\n",
        "    state_comparison.append({\n",
        "        'state': state,\n",
        "        'baseline_rmse': best_baseline_rmse,\n",
        "        'baseline_model': best_baseline_model,\n",
        "        'global_rmse': best_global_rmse,\n",
        "        'global_model': best_global_model,\n",
        "        'improvement_pct': improvement_pct,\n",
        "        'rmse_reduction': best_baseline_rmse - best_global_rmse\n",
        "    })\n",
        "\n",
        "df_comparison = pd.DataFrame(state_comparison)"
      ],
      "metadata": {
        "id": "mO5WOQOA5tkE"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nPerformance Comparison (Best Baseline vs Best Global per State):\")\n",
        "print(f\"   Mean Baseline RMSE:  {df_comparison['baseline_rmse'].mean():.2f}\")\n",
        "print(f\"   Mean Global RMSE:    {df_comparison['global_rmse'].mean():.2f}\")\n",
        "print(f\"   Mean Improvement:    {df_comparison['improvement_pct'].mean():.1f}%\")\n",
        "print(f\"   Median Improvement:  {df_comparison['improvement_pct'].median():.1f}%\")\n",
        "\n",
        "# States with improvement\n",
        "improved_count = (df_comparison['improvement_pct'] > 0).sum()\n",
        "print(f\"\\nImprovement Distribution:\")\n",
        "print(f\"   States improved:     {improved_count}/{len(df_comparison)} ({improved_count/len(df_comparison)*100:.1f}%)\")\n",
        "print(f\"   States worse:        {len(df_comparison) - improved_count}/{len(df_comparison)}\")\n",
        "print(f\"   Best improvement:    {df_comparison['improvement_pct'].max():.1f}% ({df_comparison.loc[df_comparison['improvement_pct'].idxmax(), 'state']})\")\n",
        "print(f\"   Worst case:          {df_comparison['improvement_pct'].min():.1f}% ({df_comparison.loc[df_comparison['improvement_pct'].idxmin(), 'state']})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CfuY14_k50ev",
        "outputId": "a7029679-81d6-46c5-9100-40096895eff9"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Performance Comparison (Best Baseline vs Best Global per State):\n",
            "   Mean Baseline RMSE:  34464.39\n",
            "   Mean Global RMSE:    27804.04\n",
            "   Mean Improvement:    17.4%\n",
            "   Median Improvement:  18.4%\n",
            "\n",
            "Improvement Distribution:\n",
            "   States improved:     16/16 (100.0%)\n",
            "   States worse:        0/16\n",
            "   Best improvement:    31.2% (Hessen)\n",
            "   Worst case:          4.5% (Thüringen)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n Statistical Test (Paired t-test):\")\n",
        "print(\"   Comparing: Best baseline RMSE vs Best global RMSE for each state\")\n",
        "print(\"   H0: Mean(baseline_RMSE) = Mean(global_RMSE)  [No improvement]\")\n",
        "print(\"   Ha: Mean(baseline_RMSE) > Mean(global_RMSE)  [Global models better]\")\n",
        "\n",
        "# Paired t-test (one-tailed)\n",
        "t_stat_model, p_value_model_two_tailed = stats.ttest_rel(\n",
        "    df_comparison['baseline_rmse'],\n",
        "    df_comparison['global_rmse']\n",
        ")\n",
        "\n",
        "# Converting to one-tailed (expect global to be better)\n",
        "p_value_model = p_value_model_two_tailed / 2 if t_stat_model > 0 else 1 - (p_value_model_two_tailed / 2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whhIDm0V67uU",
        "outputId": "4757dbba-1699-4b49-912b-7a8505943e41"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Statistical Test (Paired t-test):\n",
            "   Comparing: Best baseline RMSE vs Best global RMSE for each state\n",
            "   H0: Mean(baseline_RMSE) = Mean(global_RMSE)  [No improvement]\n",
            "   Ha: Mean(baseline_RMSE) > Mean(global_RMSE)  [Global models better]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"   t-statistic: {t_stat_model:.3f}\")\n",
        "print(f\"   p-value (one-tailed): {p_value_model:.6f}\")\n",
        "\n",
        "if p_value_model < 0.001:\n",
        "    print(f\"   Result: STRONGLY SIGNIFICANT (p < 0.001)\")\n",
        "elif p_value_model < 0.01:\n",
        "    print(f\"   Result: VERY SIGNIFICANT (p < 0.01)\")\n",
        "elif p_value_model < 0.05:\n",
        "    print(f\"   Result: SIGNIFICANT (p < 0.05)\")\n",
        "else:\n",
        "    print(f\"   Result: NOT SIGNIFICANT (p >= 0.05)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-wwQMOhm69pA",
        "outputId": "997b3993-83d3-4c9b-fe9e-4a036527435a"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   t-statistic: 3.888\n",
            "   p-value (one-tailed): 0.000728\n",
            "   Result: STRONGLY SIGNIFICANT (p < 0.001)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Effect size (Cohen's d for paired samples)\n",
        "differences = df_comparison['baseline_rmse'] - df_comparison['global_rmse']\n",
        "cohen_d_model = differences.mean() / differences.std()\n",
        "\n",
        "print(f\"\\n Effect Size (Cohen's d): {cohen_d_model:.3f}\")\n",
        "if abs(cohen_d_model) >= 0.8:\n",
        "    print(f\"   Interpretation: LARGE effect\")\n",
        "elif abs(cohen_d_model) >= 0.5:\n",
        "    print(f\"   Interpretation: MEDIUM effect\")\n",
        "elif abs(cohen_d_model) >= 0.2:\n",
        "    print(f\"   Interpretation: SMALL effect\")\n",
        "else:\n",
        "    print(f\"   Interpretation: NEGLIGIBLE effect\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aaItgS7c7J2T",
        "outputId": "c7c40d17-b093-4348-991a-8a171d3ceec6"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Effect Size (Cohen's d): 0.972\n",
            "   Interpretation: LARGE effect\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 95% Confidence Interval for mean improvement\n",
        "ci_lower, ci_upper = stats.t.interval(\n",
        "    0.95,\n",
        "    len(df_comparison)-1,\n",
        "    loc=df_comparison['improvement_pct'].mean(),\n",
        "    scale=stats.sem(df_comparison['improvement_pct'])\n",
        ")\n",
        "\n",
        "print(f\"\\n 95% Confidence Interval for Mean Improvement:\")\n",
        "print(f\"   [{ci_lower:.1f}%, {ci_upper:.1f}%]\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eY5_8exA7MZP",
        "outputId": "a354bfb5-09de-4519-b991-bf4f3f506a19"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " 95% Confidence Interval for Mean Improvement:\n",
            "   [13.7%, 21.2%]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BREAKDOWN BY MODEL TYPE\n",
        "\n",
        "# Most used baseline model\n",
        "baseline_model_counts = df_comparison['baseline_model'].value_counts()\n",
        "print(f\"\\n   Best Baseline Model Distribution:\")\n",
        "for model, count in baseline_model_counts.items():\n",
        "    print(f\"   • {model}: {count}/{len(df_comparison)} states ({count/len(df_comparison)*100:.1f}%)\")\n",
        "\n",
        "# Most used global model\n",
        "global_model_counts = df_comparison['global_model'].value_counts()\n",
        "print(f\"\\n   Best Global Model Distribution:\")\n",
        "for model, count in global_model_counts.items():\n",
        "    avg_improvement = df_comparison[df_comparison['global_model'] == model]['improvement_pct'].mean()\n",
        "    print(f\"   • {model}: {count}/{len(df_comparison)} states ({count/len(df_comparison)*100:.1f}%), avg improvement: {avg_improvement:.1f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nh0eORTZ5Hjd",
        "outputId": "2e7755dd-6ea6-4771-c58e-1ab8553c087b"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "   Best Baseline Model Distribution:\n",
            "   • AutoARIMA: 15/16 states (93.8%)\n",
            "   • Naive: 1/16 states (6.2%)\n",
            "\n",
            "   Best Global Model Distribution:\n",
            "   • LinearReg: 9/16 states (56.2%), avg improvement: 17.6%\n",
            "   • RandomForest: 4/16 states (25.0%), avg improvement: 12.5%\n",
            "   • LightGBM: 2/16 states (12.5%), avg improvement: 26.8%\n",
            "   • XGBoost: 1/16 states (6.2%), avg improvement: 17.2%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if p_value_model < 0.05 and df_comparison['improvement_pct'].mean() > 0:\n",
        "    print(\" HYPOTHESIS 3 STRONGLY SUPPORTED\")\n",
        "    print(f\"   Global models with labor market variables significantly outperform\")\n",
        "    print(f\"   baseline models (p = {p_value_model:.6f})\")\n",
        "    print(f\"   Average improvement: {df_comparison['improvement_pct'].mean():.1f}%\")\n",
        "    print(f\"   This proves labor market variables have PREDICTIVE POWER\")\n",
        "else:\n",
        "    print(\" HYPOTHESIS 3 NOT SUPPORTED\")\n",
        "    print(\"   Labor market variables do not significantly improve prediction accuracy\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57I9PS5u7cQT",
        "outputId": "fa7bf28f-552d-4fb3-8044-d6d51e1c55db"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " HYPOTHESIS 3 STRONGLY SUPPORTED\n",
            "   Global models with labor market variables significantly outperform\n",
            "   baseline models (p = 0.000728)\n",
            "   Average improvement: 17.4%\n",
            "   This proves labor market variables have PREDICTIVE POWER\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('results/hypothesis_testing', exist_ok=True)\n",
        "df_comparison.to_csv('results/hypothesis_testing/model_comparison.csv', index=False)\n",
        "print(f\"\\nSaved: results/hypothesis_testing/model_comparison.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-RcycuRM7iBi",
        "outputId": "aa2e4e61-aaf5-47bd-fe7e-e2bb01ec66b4"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Saved: results/hypothesis_testing/model_comparison.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Evidence from feature importance (SHAP)**"
      ],
      "metadata": {
        "id": "MnrxC_Ub77Y-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if len(feature_importance_dict) > 0:\n",
        "    all_importance = []\n",
        "\n",
        "    for model_name, df_importance in feature_importance_dict.items():\n",
        "        all_importance.append(df_importance)\n",
        "\n",
        "    df_all_importance = pd.concat(all_importance, ignore_index=True)\n",
        "\n",
        "    # Calculate average importance per feature across models\n",
        "    avg_importance = df_all_importance.groupby('Feature')['Importance_Pct'].mean().sort_values(ascending=False)\n",
        "\n",
        "    print(\"\\nAverage Feature Importance Across Models:\")\n",
        "\n",
        "    # Separate labor market vs past migration\n",
        "    labor_market_features = []\n",
        "    past_migration_features = []\n",
        "\n",
        "    for feature, importance in avg_importance.items():\n",
        "        if any(kw in feature.lower() for kw in ['unemployment', 'vacanc', 'tightness', 'unemployed']):\n",
        "            labor_market_features.append((feature, importance))\n",
        "        elif 'migration_foreign_lag' in feature.lower():\n",
        "            past_migration_features.append((feature, importance))\n",
        "\n",
        "    print(f\"\\nLabor Market Variables:\")\n",
        "    total_labor_market = 0\n",
        "    for feature, importance in labor_market_features:\n",
        "        print(f\"      • {feature:<40} {importance:>6.1f}%\")\n",
        "        total_labor_market += importance\n",
        "\n",
        "    print(f\"\\nPast Migration Patterns:\")\n",
        "    total_past_migration = 0\n",
        "    for feature, importance in past_migration_features:\n",
        "        print(f\"      • {feature:<40} {importance:>6.1f}%\")\n",
        "        total_past_migration += importance\n",
        "\n",
        "    print(f\"\\nSummary:\")\n",
        "    print(f\"   • Total Labor Market Importance:  {total_labor_market:.1f}%\")\n",
        "    print(f\"   • Total Past Migration Importance: {total_past_migration:.1f}%\")\n",
        "\n",
        "    # Top features\n",
        "    print(f\"\\nTop 5 Most Important Features:\")\n",
        "    for i, (feature, importance) in enumerate(avg_importance.head(5).items(), 1):\n",
        "        print(f\"    {i}. {feature:<40} {importance:>6.1f}%\")\n",
        "\n",
        "    # Key finding\n",
        "    labor_market_rank = []\n",
        "    for i, feature in enumerate(avg_importance.index, 1):\n",
        "        if any(kw in feature.lower() for kw in ['vacanc', 'tightness', 'unemployment', 'unemployed']):\n",
        "            labor_market_rank.append(i)\n",
        "\n",
        "    if labor_market_rank:\n",
        "        highest_labor_rank = min(labor_market_rank)\n",
        "        print(f\"\\nKey Finding:\")\n",
        "        print(f\"      Labor market variables appear in top {highest_labor_rank} features\")\n",
        "        print(f\"      This confirms they are important predictors alongside past migration\")\n",
        "\n",
        "else:\n",
        "    print(\"No feature importance data available\")\n",
        "    print(\"(Re-run notebook 4 for this analysis)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uITR_MlM8BiK",
        "outputId": "45f55657-5cbc-4ade-ce4d-f610f123f251"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average Feature Importance Across Models:\n",
            "\n",
            "Labor Market Variables:\n",
            "      • vacancies_sc_lag0                          23.9%\n",
            "      • vacancy_rate_lag0                           6.0%\n",
            "      • unemployed_count_lag0                       3.0%\n",
            "      • unemployment_rate_lag0                      2.0%\n",
            "      • labor_market_tightness_lag0                 0.0%\n",
            "\n",
            "Past Migration Patterns:\n",
            "      • migration_foreign_lag3                     57.0%\n",
            "      • migration_foreign_lag2                      6.6%\n",
            "      • migration_foreign_lag1                      1.7%\n",
            "\n",
            "Summary:\n",
            "   • Total Labor Market Importance:  34.9%\n",
            "   • Total Past Migration Importance: 65.3%\n",
            "\n",
            "Top 5 Most Important Features:\n",
            "    1. migration_foreign_lag3                     57.0%\n",
            "    2. vacancies_sc_lag0                          23.9%\n",
            "    3. migration_foreign_lag2                      6.6%\n",
            "    4. vacancy_rate_lag0                           6.0%\n",
            "    5. unemployed_count_lag0                       3.0%\n",
            "\n",
            "Key Finding:\n",
            "      Labor market variables appear in top 2 features\n",
            "      This confirms they are important predictors alongside past migration\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Report**"
      ],
      "metadata": {
        "id": "8AsDLzjI98mU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# All results\n",
        "results_summary = {\n",
        "    'analysis_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
        "    'dataset_period': f\"{df_features['year'].min()}-{df_features['year'].max()}\",\n",
        "    'n_states': len(state_names),\n",
        "    'n_observations': len(df_features),\n",
        "    'test_period': f\"{test_years[0]}-{test_years[-1]}\",\n",
        "\n",
        "    # H1 Results\n",
        "    'h1_mean_correlation': df_h1['correlation'].mean(),\n",
        "    'h1_median_correlation': df_h1['correlation'].median(),\n",
        "    'h1_positive_states': (df_h1['correlation'] > 0).sum(),\n",
        "    'h1_significant_positive': ((df_h1['correlation'] > 0) & (df_h1['significant'])).sum(),\n",
        "    'h1_p_value': p_value_h1,\n",
        "    'h1_t_statistic': t_stat_h1,\n",
        "    'h1_cohen_d': cohen_d_h1,\n",
        "    'h1_supported': bool(p_value_h1 < 0.05 and df_h1['correlation'].mean() > 0),\n",
        "\n",
        "    # H2 Results\n",
        "    'h2_mean_correlation': df_h2['correlation'].mean(),\n",
        "    'h2_median_correlation': df_h2['correlation'].median(),\n",
        "    'h2_positive_states': (df_h2['correlation'] > 0).sum(),\n",
        "    'h2_significant_positive': ((df_h2['correlation'] > 0) & (df_h2['significant'])).sum(),\n",
        "    'h2_p_value': p_value_h2,\n",
        "    'h2_t_statistic': t_stat_h2,\n",
        "    'h2_cohen_d': cohen_d_h2,\n",
        "    'h2_supported': bool(p_value_h2 < 0.05 and df_h2['correlation'].mean() > 0),\n",
        "\n",
        "    # Model Comparison Results\n",
        "    'baseline_mean_rmse': df_comparison['baseline_rmse'].mean(),\n",
        "    'global_mean_rmse': df_comparison['global_rmse'].mean(),\n",
        "    'mean_improvement_pct': df_comparison['improvement_pct'].mean(),\n",
        "    'median_improvement_pct': df_comparison['improvement_pct'].median(),\n",
        "    'states_improved': (df_comparison['improvement_pct'] > 0).sum(),\n",
        "    'model_comparison_p_value': p_value_model,\n",
        "    'model_comparison_t_stat': t_stat_model,\n",
        "    'model_comparison_cohen_d': cohen_d_model,\n",
        "    'h3_supported': bool(p_value_model < 0.05 and df_comparison['improvement_pct'].mean() > 0),\n",
        "}\n",
        "\n",
        "pd.DataFrame([results_summary]).to_csv('results/hypothesis_testing/summary_statistics.csv', index=False)\n",
        "print(\"Saved: results/hypothesis_testing/summary_statistics.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVBg-TYb-er6",
        "outputId": "c712e52a-0574-4246-fccc-ef737238a749"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: results/hypothesis_testing/summary_statistics.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Text report\n",
        "report_lines = []\n",
        "\n",
        "report_lines.append(\"=\"*80)\n",
        "report_lines.append(\"FINAL RESEARCH REPORT\")\n",
        "report_lines.append(\"Migration and Labor Market Dynamics in Germany (2000-2024)\")\n",
        "report_lines.append(\"=\"*80)\n",
        "\n",
        "report_lines.append(f\"\\nAnalysis Date: {results_summary['analysis_date']}\")\n",
        "report_lines.append(f\"Dataset: {results_summary['n_states']} German states, {results_summary['dataset_period']}\")\n",
        "report_lines.append(f\"Total Observations: {results_summary['n_observations']}\")\n",
        "report_lines.append(f\"Test Period: {results_summary['test_period']}\")\n",
        "\n",
        "# Research Questions\n",
        "\n",
        "report_lines.append(\"\\n\" + \"=\"*80)\n",
        "report_lines.append(\"RESEARCH QUESTIONS\")\n",
        "report_lines.append(\"=\"*80)\n",
        "\n",
        "report_lines.append(\"\\n1. Do job vacancies predict foreign migration patterns?\")\n",
        "report_lines.append(\"2. Does labor market tightness predict foreign migration patterns?\")\n",
        "report_lines.append(\"3. Can labor market indicators improve migration forecasts?\")\n",
        "\n",
        "# Methodology\n",
        "\n",
        "report_lines.append(\"\\n\" + \"=\"*80)\n",
        "report_lines.append(\"METHODOLOGY\")\n",
        "report_lines.append(\"=\"*80)\n",
        "\n",
        "report_lines.append(\"\\nData Analysis Approach:\")\n",
        "report_lines.append(\"   • Correlation analysis (Pearson) for H1 and H2\")\n",
        "report_lines.append(\"   • Global forecasting models trained on 16 states simultaneously\")\n",
        "report_lines.append(\"   • Baseline models: Naive, AutoARIMA (no covariates)\")\n",
        "report_lines.append(\"   • Global models: LinearReg, RandomForest, XGBoost, LightGBM (with covariates)\")\n",
        "report_lines.append(\"   • SHAP explainability for feature importance\")\n",
        "report_lines.append(\"   • Statistical significance testing (α = 0.05)\")\n",
        "\n",
        "report_lines.append(\"\\nKey Variables:\")\n",
        "report_lines.append(\"   Target: migration_foreign (foreign migration balance)\")\n",
        "report_lines.append(\"   Covariates:\")\n",
        "report_lines.append(\"     • unemployment_rate\")\n",
        "report_lines.append(\"     • vacancies_sc (job vacancies subject to social contributions)\")\n",
        "report_lines.append(\"     • labor_market_tightness (vacancies/unemployed)\")\n",
        "report_lines.append(\"     • unemployed_count\")\n",
        "report_lines.append(\"     • vacancy_rate\")\n",
        "\n",
        "# Key findings\n",
        "\n",
        "report_lines.append(\"\\n\" + \"=\"*80)\n",
        "report_lines.append(\"KEY FINDINGS\")\n",
        "report_lines.append(\"=\"*80)\n",
        "\n",
        "# H1\n",
        "report_lines.append(\"\\n\" + \"-\"*80)\n",
        "report_lines.append(\"HYPOTHESIS 1: Job Vacancies → Foreign Migration\")\n",
        "report_lines.append(\"-\"*80)\n",
        "\n",
        "if results_summary['h1_supported']:\n",
        "    report_lines.append(\"STRONGLY SUPPORTED\")\n",
        "else:\n",
        "    report_lines.append(\"NOT SUPPORTED\")\n",
        "\n",
        "report_lines.append(f\"\\nEvidence:\")\n",
        "report_lines.append(f\"   • Mean correlation: r = {results_summary['h1_mean_correlation']:.3f}\")\n",
        "report_lines.append(f\"   • Positive correlation in {results_summary['h1_positive_states']}/{results_summary['n_states']} states ({results_summary['h1_positive_states']/results_summary['n_states']*100:.1f}%)\")\n",
        "report_lines.append(f\"   • Significant positive in {results_summary['h1_significant_positive']}/{results_summary['n_states']} states\")\n",
        "report_lines.append(f\"   • Statistical test: t = {results_summary['h1_t_statistic']:.3f}, p = {results_summary['h1_p_value']:}\")\n",
        "effect_size_h1 = \"LARGE\" if abs(results_summary['h1_cohen_d']) >= 0.8 else \\\n",
        "                 \"MEDIUM\" if abs(results_summary['h1_cohen_d']) >= 0.5 else \"SMALL\"\n",
        "report_lines.append(f\"   • Effect size: Cohen's d = {results_summary['h1_cohen_d']:.3f} ({effect_size_h1})\")\n",
        "\n",
        "# H2\n",
        "report_lines.append(\"\\n\" + \"-\"*80)\n",
        "report_lines.append(\"HYPOTHESIS 2: Labor Market Tightness → Foreign Migration\")\n",
        "report_lines.append(\"-\"*80)\n",
        "\n",
        "if results_summary['h2_supported']:\n",
        "    report_lines.append(\"STRONGLY SUPPORTED\")\n",
        "else:\n",
        "    report_lines.append(\"NOT SUPPORTED\")\n",
        "\n",
        "report_lines.append(f\"\\nEvidence:\")\n",
        "report_lines.append(f\"   • Mean correlation: r = {results_summary['h2_mean_correlation']:.3f}\")\n",
        "report_lines.append(f\"   • Positive correlation in {results_summary['h2_positive_states']}/{results_summary['n_states']} states ({results_summary['h2_positive_states']/results_summary['n_states']*100:.1f}%)\")\n",
        "report_lines.append(f\"   • Significant positive in {results_summary['h2_significant_positive']}/{results_summary['n_states']} states\")\n",
        "report_lines.append(f\"   • Statistical test: t = {results_summary['h2_t_statistic']:.3f}, p = {results_summary['h2_p_value']:}\")\n",
        "effect_size_h2 = \"LARGE\" if abs(results_summary['h2_cohen_d']) >= 0.8 else \\\n",
        "                 \"MEDIUM\" if abs(results_summary['h2_cohen_d']) >= 0.5 else \"SMALL\"\n",
        "report_lines.append(f\"   • Effect size: Cohen's d = {results_summary['h2_cohen_d']:.3f} ({effect_size_h2})\")\n",
        "\n",
        "# H3 - Model Comparison\n",
        "report_lines.append(\"\\n\" + \"-\"*80)\n",
        "report_lines.append(\"HYPOTHESIS 3: Labor Market Variables Improve Prediction Accuracy\")\n",
        "report_lines.append(\"-\"*80)\n",
        "\n",
        "if results_summary['h3_supported']:\n",
        "    report_lines.append(\"STRONGLY SUPPORTED\")\n",
        "else:\n",
        "    report_lines.append(\"NOT SUPPORTED\")\n",
        "\n",
        "report_lines.append(f\"\\nModel Performance:\")\n",
        "report_lines.append(f\"   • Baseline (no covariates):    RMSE = {results_summary['baseline_mean_rmse']:.2f}\")\n",
        "report_lines.append(f\"   • Global models (with covariates): RMSE = {results_summary['global_mean_rmse']:.2f}\")\n",
        "report_lines.append(f\"   • Mean improvement: {results_summary['mean_improvement_pct']:.1f}%\")\n",
        "report_lines.append(f\"   • States improved: {results_summary['states_improved']}/{results_summary['n_states']} ({results_summary['states_improved']/results_summary['n_states']*100:.1f}%)\")\n",
        "report_lines.append(f\"   • Statistical test: t = {results_summary['model_comparison_t_stat']:.3f}, p = {results_summary['model_comparison_p_value']:}\")\n",
        "effect_size_h3 = \"LARGE\" if abs(results_summary['model_comparison_cohen_d']) >= 0.8 else \\\n",
        "                 \"MEDIUM\" if abs(results_summary['model_comparison_cohen_d']) >= 0.5 else \"SMALL\"\n",
        "report_lines.append(f\"   • Effect size: Cohen's d = {results_summary['model_comparison_cohen_d']:.3f} ({effect_size_h3})\")\n",
        "\n",
        "# Feature Importance\n",
        "if len(feature_importance_dict) > 0:\n",
        "    report_lines.append(\"\\n\" + \"-\"*80)\n",
        "    report_lines.append(\"SUPPORTING EVIDENCE: Feature Importance (SHAP Analysis)\")\n",
        "    report_lines.append(\"-\"*80)\n",
        "\n",
        "    report_lines.append(f\"\\nKey Features for Best Model:\")\n",
        "    for model_name, df_importance in feature_importance_dict.items():\n",
        "        report_lines.append(f\"\\n   Model: {model_name}\")\n",
        "        report_lines.append(f\"   Top 5 Features:\")\n",
        "        for idx, row in df_importance.head(5).iterrows():\n",
        "            report_lines.append(f\"      {row['Rank']}. {row['Feature']:<40} {row['Importance_Pct']:>5.1f}%\")\n",
        "\n",
        "        # Calculate category totals\n",
        "        labor_market_pct = df_importance[\n",
        "            df_importance['Feature'].str.contains('unemployment|vacanc|tightness|unemployed', case=False)\n",
        "        ]['Importance_Pct'].sum()\n",
        "\n",
        "        past_migration_pct = df_importance[\n",
        "            df_importance['Feature'].str.contains('migration_foreign_lag', case=False)\n",
        "        ]['Importance_Pct'].sum()\n",
        "\n",
        "        report_lines.append(f\"\\n   Category Breakdown:\")\n",
        "        report_lines.append(f\"      Labor Market Variables:  {labor_market_pct:.1f}%\")\n",
        "        report_lines.append(f\"      Past Migration Patterns: {past_migration_pct:.1f}%\")\n",
        "\n",
        "# Overall Conclusion\n",
        "\n",
        "report_lines.append(\"\\n\" + \"=\"*80)\n",
        "report_lines.append(\"OVERALL CONCLUSIONS\")\n",
        "report_lines.append(\"=\"*80)\n",
        "\n",
        "# Count number of supported hypotheses\n",
        "supported_count = sum([\n",
        "    results_summary['h1_supported'],\n",
        "    results_summary['h2_supported'],\n",
        "    results_summary['h3_supported']\n",
        "])\n",
        "\n",
        "report_lines.append(f\"\\nSummary: {supported_count}/3 hypotheses strongly supported\")\n",
        "\n",
        "if supported_count == 3:\n",
        "    report_lines.append(\"\\nRESEARCH OBJECTIVES ACHIEVED\")\n",
        "    report_lines.append(\"\\nThis study provides strong, triangulated evidence that labor market\")\n",
        "    report_lines.append(\"indicators significantly predict and improve forecasts of foreign migration\")\n",
        "    report_lines.append(\"patterns across all 16 German states.\")\n",
        "\n",
        "    report_lines.append(\"\\nThree Lines of Evidence:\")\n",
        "    report_lines.append(f\"   1. Correlation Analysis: Both job vacancies (r={results_summary['h1_mean_correlation']:.3f}) and\")\n",
        "    report_lines.append(f\"      labor market tightness (r={results_summary['h2_mean_correlation']:.3f}) strongly correlate\")\n",
        "    report_lines.append(f\"      with migration (both p<0.001)\")\n",
        "\n",
        "    report_lines.append(f\"\\n   2. Predictive Power: Models using labor market variables are\")\n",
        "    report_lines.append(f\"      {results_summary['mean_improvement_pct']:.1f}% more accurate than baseline models\")\n",
        "    report_lines.append(f\"      (p={results_summary['model_comparison_p_value']:.6f})\")\n",
        "\n",
        "    if len(feature_importance_dict) > 0:\n",
        "        report_lines.append(f\"\\n   3. Feature Importance: SHAP analysis confirms labor market\")\n",
        "        report_lines.append(f\"      variables are among the top predictive features\")\n",
        "\n",
        "elif supported_count >= 2:\n",
        "    report_lines.append(\"\\nPARTIAL SUPPORT\")\n",
        "    report_lines.append(\"\\nThe research provides moderate evidence for the role of labor market\")\n",
        "    report_lines.append(\"indicators in migration patterns, though not all hypotheses were supported.\")\n",
        "\n",
        "else:\n",
        "    report_lines.append(\"\\nLIMITED SUPPORT\")\n",
        "    report_lines.append(\"\\nThe evidence does not strongly support the hypothesis that labor market\")\n",
        "    report_lines.append(\"indicators predict migration patterns in this dataset.\")\n",
        "\n",
        "# Limitatiosn\n",
        "\n",
        "report_lines.append(\"\\n\" + \"=\"*80)\n",
        "report_lines.append(\"LIMITATIONS\")\n",
        "report_lines.append(\"=\"*80)\n",
        "\n",
        "report_lines.append(\"\\nStudy Limitations:\")\n",
        "report_lines.append(\"   • Limited to 25 years of data (2000-2024)\")\n",
        "report_lines.append(\"   • Yearly aggregation misses within-year dynamics\")\n",
        "report_lines.append(\"   • Omitted variables:\")\n",
        "report_lines.append(\"     - Housing costs and availability\")\n",
        "report_lines.append(\"     - Education quality and university rankings\")\n",
        "report_lines.append(\"     - Cultural amenities and quality of life\")\n",
        "report_lines.append(\"     - Social networks and diaspora effects\")\n",
        "report_lines.append(\"     - Immigration policy changes\")\n",
        "report_lines.append(\"   • Correlation does not prove causation\")\n",
        "report_lines.append(\"   • Model performance varies by state (heterogeneity)\")\n",
        "\n",
        "# Future Research\n",
        "\n",
        "report_lines.append(\"\\n\" + \"=\"*80)\n",
        "report_lines.append(\"FUTURE RESEARCH DIRECTIONS\")\n",
        "report_lines.append(\"=\"*80)\n",
        "\n",
        "report_lines.append(\"\\nRecommended Extensions:\")\n",
        "report_lines.append(\"   1. Include additional covariates:\")\n",
        "report_lines.append(\"      • Housing market indicators\")\n",
        "report_lines.append(\"      • GDP growth and regional economic indicators\")\n",
        "report_lines.append(\"      • Education and amenity indices\")\n",
        "report_lines.append(\"      • Cultural diversity measures\")\n",
        "report_lines.append(\"\\n   2. Test causality:\")\n",
        "report_lines.append(\"      • Granger causality tests\")\n",
        "report_lines.append(\"      • Instrumental variable analysis\")\n",
        "report_lines.append(\"      • Difference-in-differences (policy changes)\")\n",
        "report_lines.append(\"\\n   3. Extend analysis:\")\n",
        "report_lines.append(\"      • Analyze specific nationality groups separately\")\n",
        "report_lines.append(\"      • Use monthly/quarterly data for higher resolution\")\n",
        "report_lines.append(\"      • Compare with other European countries\")\n",
        "report_lines.append(\"      • Investigate regional spillover effects\")\n",
        "\n",
        "report_text = \"\\n\".join(report_lines)\n",
        "\n",
        "report_path = 'results/FINAL_REPORT.txt'\n",
        "with open(report_path, 'w', encoding='utf-8') as f:\n",
        "    f.write(report_text)\n",
        "\n",
        "print(f\"\\nSaved: {report_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frWhbP2W-Df6",
        "outputId": "563c4c78-5850-43b4-948c-8db8ca2c7fd9"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Saved: results/FINAL_REPORT.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"REPORT PREVIEW\")\n",
        "print(\"=\"*80)\n",
        "print(report_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X329RFMBAN2_",
        "outputId": "41e171b2-9cae-4caa-fc65-e52c3eab411e"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "REPORT PREVIEW\n",
            "================================================================================\n",
            "================================================================================\n",
            "FINAL RESEARCH REPORT\n",
            "Migration and Labor Market Dynamics in Germany (2000-2024)\n",
            "================================================================================\n",
            "\n",
            "Analysis Date: 2026-01-13 15:29:33\n",
            "Dataset: 16 German states, 2000-2024\n",
            "Total Observations: 400\n",
            "Test Period: 2020-2024\n",
            "\n",
            "================================================================================\n",
            "RESEARCH QUESTIONS\n",
            "================================================================================\n",
            "\n",
            "1. Do job vacancies predict foreign migration patterns?\n",
            "2. Does labor market tightness predict foreign migration patterns?\n",
            "3. Can labor market indicators improve migration forecasts?\n",
            "\n",
            "================================================================================\n",
            "METHODOLOGY\n",
            "================================================================================\n",
            "\n",
            "Data Analysis Approach:\n",
            "   • Correlation analysis (Pearson) for H1 and H2\n",
            "   • Global forecasting models trained on 16 states simultaneously\n",
            "   • Baseline models: Naive, AutoARIMA (no covariates)\n",
            "   • Global models: LinearReg, RandomForest, XGBoost, LightGBM (with covariates)\n",
            "   • SHAP explainability for feature importance\n",
            "   • Statistical significance testing (α = 0.05)\n",
            "\n",
            "Key Variables:\n",
            "   Target: migration_foreign (foreign migration balance)\n",
            "   Covariates:\n",
            "     • unemployment_rate\n",
            "     • vacancies_sc (job vacancies subject to social contributions)\n",
            "     • labor_market_tightness (vacancies/unemployed)\n",
            "     • unemployed_count\n",
            "     • vacancy_rate\n",
            "\n",
            "================================================================================\n",
            "KEY FINDINGS\n",
            "================================================================================\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "HYPOTHESIS 1: Job Vacancies → Foreign Migration\n",
            "--------------------------------------------------------------------------------\n",
            "STRONGLY SUPPORTED\n",
            "\n",
            "Evidence:\n",
            "   • Mean correlation: r = 0.640\n",
            "   • Positive correlation in 16/16 states (100.0%)\n",
            "   • Significant positive in 15/16 states\n",
            "   • Statistical test: t = 18.422, p = 1.0344758080389701e-11\n",
            "   • Effect size: Cohen's d = 4.605 (LARGE)\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "HYPOTHESIS 2: Labor Market Tightness → Foreign Migration\n",
            "--------------------------------------------------------------------------------\n",
            "STRONGLY SUPPORTED\n",
            "\n",
            "Evidence:\n",
            "   • Mean correlation: r = 0.639\n",
            "   • Positive correlation in 16/16 states (100.0%)\n",
            "   • Significant positive in 15/16 states\n",
            "   • Statistical test: t = 19.384, p = 4.96364592987353e-12\n",
            "   • Effect size: Cohen's d = 4.846 (LARGE)\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "HYPOTHESIS 3: Labor Market Variables Improve Prediction Accuracy\n",
            "--------------------------------------------------------------------------------\n",
            "STRONGLY SUPPORTED\n",
            "\n",
            "Model Performance:\n",
            "   • Baseline (no covariates):    RMSE = 34464.39\n",
            "   • Global models (with covariates): RMSE = 27804.04\n",
            "   • Mean improvement: 17.4%\n",
            "   • States improved: 16/16 (100.0%)\n",
            "   • Statistical test: t = 3.888, p = 0.0007279156924670929\n",
            "   • Effect size: Cohen's d = 0.972 (LARGE)\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "SUPPORTING EVIDENCE: Feature Importance (SHAP Analysis)\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Key Features for Best Model:\n",
            "\n",
            "   Model: LinearReg\n",
            "   Top 5 Features:\n",
            "      1. migration_foreign_lag3                    57.0%\n",
            "      2. vacancies_sc_lag0                         23.9%\n",
            "      3. migration_foreign_lag2                     6.6%\n",
            "      4. vacancy_rate_lag0                          6.0%\n",
            "      5. unemployed_count_lag0                      3.0%\n",
            "\n",
            "   Category Breakdown:\n",
            "      Labor Market Variables:  34.9%\n",
            "      Past Migration Patterns: 65.3%\n",
            "\n",
            "================================================================================\n",
            "OVERALL CONCLUSIONS\n",
            "================================================================================\n",
            "\n",
            "Summary: 3/3 hypotheses strongly supported\n",
            "\n",
            "RESEARCH OBJECTIVES ACHIEVED\n",
            "\n",
            "This study provides strong, triangulated evidence that labor market\n",
            "indicators significantly predict and improve forecasts of foreign migration\n",
            "patterns across all 16 German states.\n",
            "\n",
            "Three Lines of Evidence:\n",
            "   1. Correlation Analysis: Both job vacancies (r=0.640) and\n",
            "      labor market tightness (r=0.639) strongly correlate\n",
            "      with migration (both p<0.001)\n",
            "\n",
            "   2. Predictive Power: Models using labor market variables are\n",
            "      17.4% more accurate than baseline models\n",
            "      (p=0.000728)\n",
            "\n",
            "   3. Feature Importance: SHAP analysis confirms labor market\n",
            "      variables are among the top predictive features\n",
            "\n",
            "================================================================================\n",
            "LIMITATIONS\n",
            "================================================================================\n",
            "\n",
            "Study Limitations:\n",
            "   • Limited to 25 years of data (2000-2024)\n",
            "   • Yearly aggregation misses within-year dynamics\n",
            "   • Omitted variables:\n",
            "     - Housing costs and availability\n",
            "     - Education quality and university rankings\n",
            "     - Cultural amenities and quality of life\n",
            "     - Social networks and diaspora effects\n",
            "     - Immigration policy changes\n",
            "   • Correlation does not prove causation\n",
            "   • Model performance varies by state (heterogeneity)\n",
            "\n",
            "================================================================================\n",
            "FUTURE RESEARCH DIRECTIONS\n",
            "================================================================================\n",
            "\n",
            "Recommended Extensions:\n",
            "   1. Include additional covariates:\n",
            "      • Housing market indicators\n",
            "      • GDP growth and regional economic indicators\n",
            "      • Education and amenity indices\n",
            "      • Cultural diversity measures\n",
            "\n",
            "   2. Test causality:\n",
            "      • Granger causality tests\n",
            "      • Instrumental variable analysis\n",
            "      • Difference-in-differences (policy changes)\n",
            "\n",
            "   3. Extend analysis:\n",
            "      • Analyze specific nationality groups separately\n",
            "      • Use monthly/quarterly data for higher resolution\n",
            "      • Compare with other European countries\n",
            "      • Investigate regional spillover effects\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Nu1Dp5OU17XI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}